//! Unit tests for reshape operations (pivot, melt, transpose, stack/unstack)
//!
//! Test coverage:
//! - Pivot table with different aggregation functions
//! - Edge cases (single value, missing combinations, duplicates)
//! - Type support (Int64, Float64, Bool for index/columns)
//! - Large datasets (10K rows)
//! - Memory leak validation (1000 iterations)

const std = @import("std");
const testing = std.testing;
const DataFrame = @import("../../../core/dataframe.zig").DataFrame;
const Series = @import("../../../core/series.zig").Series;
const reshape = @import("../../../core/reshape.zig");
const types = @import("../../../core/types.zig");
const ColumnDesc = types.ColumnDesc;
const ValueType = types.ValueType;

// Helper: Create test DataFrame for pivot operations
fn createPivotTestData(allocator: std.mem.Allocator) !DataFrame {
    // Create long-format data:
    // date, region, sales
    // 2024-01-01, East, 100
    // 2024-01-01, West, 200
    // 2024-01-01, South, 150
    // 2024-01-02, East, 120
    // 2024-01-02, West, 180
    // 2024-01-02, South, 160

    const row_count: u32 = 6;
    const columns = [_]ColumnDesc{
        ColumnDesc.init("date", .Int64, 0),
        ColumnDesc.init("region", .String, 1),
        ColumnDesc.init("sales", .Int64, 2),
    };

    var df = try DataFrame.create(allocator, &columns, row_count);

    // Fill date column (20240101, 20240102)
    df.columns[0].data.Int64[0] = 20240101;
    df.columns[0].data.Int64[1] = 20240101;
    df.columns[0].data.Int64[2] = 20240101;
    df.columns[0].data.Int64[3] = 20240102;
    df.columns[0].data.Int64[4] = 20240102;
    df.columns[0].data.Int64[5] = 20240102;

    // Fill region column
    try df.columns[1].appendString(allocator, "East");
    try df.columns[1].appendString(allocator, "West");
    try df.columns[1].appendString(allocator, "South");
    try df.columns[1].appendString(allocator, "East");
    try df.columns[1].appendString(allocator, "West");
    try df.columns[1].appendString(allocator, "South");

    // Fill sales column
    df.columns[2].data.Int64[0] = 100;
    df.columns[2].data.Int64[1] = 200;
    df.columns[2].data.Int64[2] = 150;
    df.columns[2].data.Int64[3] = 120;
    df.columns[2].data.Int64[4] = 180;
    df.columns[2].data.Int64[5] = 160;

    // Update DataFrame row count and series lengths
    df.row_count = row_count;
    df.columns[0].length = row_count;
    df.columns[2].length = row_count;

    return df;
}

test "pivot: basic sum aggregation" {
    const allocator = testing.allocator;

    var df = try createPivotTestData(allocator);
    defer df.deinit();

    // Pivot: date × region, sum(sales)
    var pivoted = try reshape.pivot(&df, allocator, .{
        .index = "date",
        .columns = "region",
        .values = "sales",
        .aggfunc = .Sum,
    });
    defer pivoted.deinit();

    // Verify structure: 2 rows (dates), 4 columns (date + 3 regions)
    try testing.expectEqual(@as(u32, 2), pivoted.row_count);
    try testing.expectEqual(@as(usize, 4), pivoted.columns.len);

    // Verify column names
    try testing.expectEqualStrings("date", pivoted.columns[0].name);
    // Columns are: date, East, West, South (order may vary)

    // Verify date values
    try testing.expectEqual(@as(i64, 20240101), pivoted.columns[0].data.Int64[0]);
    try testing.expectEqual(@as(i64, 20240102), pivoted.columns[0].data.Int64[1]);

    // Verify aggregated values exist (exact column order may vary)
    // Each region should have 2 values (one per date)
    var found_east = false;
    var found_west = false;
    var found_south = false;

    var col_idx: usize = 1;
    while (col_idx < pivoted.columns.len) : (col_idx += 1) {
        const col_name = pivoted.columns[col_idx].name;
        const values = pivoted.columns[col_idx].data.Float64;

        if (std.mem.eql(u8, col_name, "East")) {
            found_east = true;
            try testing.expectEqual(@as(f64, 100.0), values[0]);
            try testing.expectEqual(@as(f64, 120.0), values[1]);
        } else if (std.mem.eql(u8, col_name, "West")) {
            found_west = true;
            try testing.expectEqual(@as(f64, 200.0), values[0]);
            try testing.expectEqual(@as(f64, 180.0), values[1]);
        } else if (std.mem.eql(u8, col_name, "South")) {
            found_south = true;
            try testing.expectEqual(@as(f64, 150.0), values[0]);
            try testing.expectEqual(@as(f64, 160.0), values[1]);
        }
    }

    try testing.expect(found_east);
    try testing.expect(found_west);
    try testing.expect(found_south);
}

test "pivot: mean aggregation" {
    const allocator = testing.allocator;

    var df = try createPivotTestData(allocator);
    defer df.deinit();

    var pivoted = try reshape.pivot(&df, allocator, .{
        .index = "date",
        .columns = "region",
        .values = "sales",
        .aggfunc = .Mean,
    });
    defer pivoted.deinit();

    try testing.expectEqual(@as(u32, 2), pivoted.row_count);

    // Mean of single values should equal the values themselves
    var col_idx: usize = 1;
    while (col_idx < pivoted.columns.len) : (col_idx += 1) {
        const col_name = pivoted.columns[col_idx].name;
        const values = pivoted.columns[col_idx].data.Float64;

        if (std.mem.eql(u8, col_name, "East")) {
            try testing.expectApproxEqAbs(@as(f64, 100.0), values[0], 0.01);
            try testing.expectApproxEqAbs(@as(f64, 120.0), values[1], 0.01);
        }
    }
}

test "pivot: count aggregation" {
    const allocator = testing.allocator;

    var df = try createPivotTestData(allocator);
    defer df.deinit();

    var pivoted = try reshape.pivot(&df, allocator, .{
        .index = "date",
        .columns = "region",
        .values = "sales",
        .aggfunc = .Count,
    });
    defer pivoted.deinit();

    // Each cell should have count = 1 (no duplicates in test data)
    var col_idx: usize = 1;
    while (col_idx < pivoted.columns.len) : (col_idx += 1) {
        const values = pivoted.columns[col_idx].data.Float64;
        try testing.expectEqual(@as(f64, 1.0), values[0]);
        try testing.expectEqual(@as(f64, 1.0), values[1]);
    }
}

test "pivot: min/max aggregation" {
    const allocator = testing.allocator;

    var df = try createPivotTestData(allocator);
    defer df.deinit();

    var pivoted_min = try reshape.pivot(&df, allocator, .{
        .index = "date",
        .columns = "region",
        .values = "sales",
        .aggfunc = .Min,
    });
    defer pivoted_min.deinit();

    var pivoted_max = try reshape.pivot(&df, allocator, .{
        .index = "date",
        .columns = "region",
        .values = "sales",
        .aggfunc = .Max,
    });
    defer pivoted_max.deinit();

    // Min and Max should equal Sum for single values
    var col_idx: usize = 1;
    while (col_idx < pivoted_min.columns.len) : (col_idx += 1) {
        const min_vals = pivoted_min.columns[col_idx].data.Float64;
        const max_vals = pivoted_max.columns[col_idx].data.Float64;

        // Min and max should be equal (only 1 value per cell)
        try testing.expectEqual(min_vals[0], max_vals[0]);
        try testing.expectEqual(min_vals[1], max_vals[1]);
    }
}

test "pivot: duplicate values aggregated" {
    const allocator = testing.allocator;

    // Create data with duplicates:
    // date, region, sales
    // 2024-01-01, East, 100
    // 2024-01-01, East, 50  <- duplicate
    const row_count: u32 = 2;
    const columns = [_]ColumnDesc{
        ColumnDesc.init("date", .Int64, 0),
        ColumnDesc.init("region", .String, 1),
        ColumnDesc.init("sales", .Int64, 2),
    };

    var df = try DataFrame.create(allocator, &columns, row_count);
    defer df.deinit();

    df.columns[0].data.Int64[0] = 20240101;
    df.columns[0].data.Int64[1] = 20240101;

    try df.columns[1].appendString(allocator, "East");
    try df.columns[1].appendString(allocator, "East");

    df.columns[2].data.Int64[0] = 100;
    df.columns[2].data.Int64[1] = 50;

    // Update DataFrame row count and series lengths
    df.row_count = row_count;
    df.columns[0].length = row_count;
    df.columns[2].length = row_count;

    // Pivot with sum
    var pivoted = try reshape.pivot(&df, allocator, .{
        .index = "date",
        .columns = "region",
        .values = "sales",
        .aggfunc = .Sum,
    });
    defer pivoted.deinit();

    // Should have 1 row (one date), 2 columns (date + East)
    try testing.expectEqual(@as(u32, 1), pivoted.row_count);
    try testing.expectEqual(@as(usize, 2), pivoted.columns.len);

    // East column should have sum = 150
    const east_col = pivoted.columns[1];
    try testing.expectEqual(@as(f64, 150.0), east_col.data.Float64[0]);
}

test "pivot: Float64 index column" {
    const allocator = testing.allocator;

    const row_count: u32 = 2;
    const columns = [_]ColumnDesc{
        ColumnDesc.init("price", .Float64, 0),
        ColumnDesc.init("category", .String, 1),
        ColumnDesc.init("quantity", .Int64, 2),
    };

    var df = try DataFrame.create(allocator, &columns, row_count);
    defer df.deinit();

    df.columns[0].data.Float64[0] = 19.99;
    df.columns[0].data.Float64[1] = 29.99;

    try df.columns[1].appendString(allocator, "A");
    try df.columns[1].appendString(allocator, "B");

    df.columns[2].data.Int64[0] = 10;
    df.columns[2].data.Int64[1] = 5;

    // Update DataFrame row count and series lengths
    df.row_count = row_count;
    df.columns[0].length = row_count;
    df.columns[2].length = row_count;

    var pivoted = try reshape.pivot(&df, allocator, .{
        .index = "price",
        .columns = "category",
        .values = "quantity",
        .aggfunc = .Sum,
    });
    defer pivoted.deinit();

    try testing.expectEqual(@as(u32, 2), pivoted.row_count);
    try testing.expectEqual(ValueType.Float64, pivoted.columns[0].value_type);
}

test "pivot: missing combinations filled with 0.0" {
    const allocator = testing.allocator;

    // Create data with missing combinations:
    // date, region, sales
    // 2024-01-01, East, 100
    // 2024-01-02, West, 200
    // (No East on 01-02, no West on 01-01)

    const row_count: u32 = 2;
    const columns = [_]ColumnDesc{
        ColumnDesc.init("date", .Int64, 0),
        ColumnDesc.init("region", .String, 1),
        ColumnDesc.init("sales", .Int64, 2),
    };

    var df = try DataFrame.create(allocator, &columns, row_count);
    defer df.deinit();

    df.columns[0].data.Int64[0] = 20240101;
    df.columns[0].data.Int64[1] = 20240102;

    try df.columns[1].appendString(allocator, "East");
    try df.columns[1].appendString(allocator, "West");

    df.columns[2].data.Int64[0] = 100;
    df.columns[2].data.Int64[1] = 200;

    // Update DataFrame row count and series lengths
    df.row_count = row_count;
    df.columns[0].length = row_count;
    df.columns[2].length = row_count;

    var pivoted = try reshape.pivot(&df, allocator, .{
        .index = "date",
        .columns = "region",
        .values = "sales",
        .aggfunc = .Sum,
    });
    defer pivoted.deinit();

    // Should have 2 rows, 3 columns (date + East + West)
    try testing.expectEqual(@as(u32, 2), pivoted.row_count);
    try testing.expectEqual(@as(usize, 3), pivoted.columns.len);

    // Find East and West columns, check for 0.0 in missing cells (not NaN)
    var found_zero = false;
    var col_idx: usize = 1;
    while (col_idx < pivoted.columns.len) : (col_idx += 1) {
        const col_name = pivoted.columns[col_idx].name;
        const values = pivoted.columns[col_idx].data.Float64;

        if (std.mem.eql(u8, col_name, "East")) {
            // East: 100 on date 0, 0.0 on date 1 (missing)
            try testing.expectEqual(@as(f64, 100.0), values[0]);
            if (values[1] == 0.0) {
                found_zero = true;
            }
        } else if (std.mem.eql(u8, col_name, "West")) {
            // West: 0.0 on date 0 (missing), 200 on date 1
            if (values[0] == 0.0) {
                found_zero = true;
            }
            try testing.expectEqual(@as(f64, 200.0), values[1]);
        }
    }

    try testing.expect(found_zero);
}

test "pivot: single row" {
    const allocator = testing.allocator;

    const row_count: u32 = 1;
    const columns = [_]ColumnDesc{
        ColumnDesc.init("id", .Int64, 0),
        ColumnDesc.init("category", .String, 1),
        ColumnDesc.init("value", .Int64, 2),
    };

    var df = try DataFrame.create(allocator, &columns, row_count);
    defer df.deinit();

    df.columns[0].data.Int64[0] = 1;
    try df.columns[1].appendString(allocator, "A");
    df.columns[2].data.Int64[0] = 42;

    // Update DataFrame row count and series lengths
    df.row_count = row_count;
    df.columns[0].length = row_count;
    df.columns[2].length = row_count;

    var pivoted = try reshape.pivot(&df, allocator, .{
        .index = "id",
        .columns = "category",
        .values = "value",
        .aggfunc = .Sum,
    });
    defer pivoted.deinit();

    try testing.expectEqual(@as(u32, 1), pivoted.row_count);
    try testing.expectEqual(@as(usize, 2), pivoted.columns.len);
}

test "pivot: invalid column names return error" {
    const allocator = testing.allocator;

    var df = try createPivotTestData(allocator);
    defer df.deinit();

    // Non-existent index column
    try testing.expectError(error.ColumnNotFound, reshape.pivot(&df, allocator, .{
        .index = "nonexistent",
        .columns = "region",
        .values = "sales",
        .aggfunc = .Sum,
    }));

    // Non-existent columns column
    try testing.expectError(error.ColumnNotFound, reshape.pivot(&df, allocator, .{
        .index = "date",
        .columns = "nonexistent",
        .values = "sales",
        .aggfunc = .Sum,
    }));

    // Non-existent values column
    try testing.expectError(error.ColumnNotFound, reshape.pivot(&df, allocator, .{
        .index = "date",
        .columns = "region",
        .values = "nonexistent",
        .aggfunc = .Sum,
    }));
}

test "pivot: non-numeric values column returns error" {
    const allocator = testing.allocator;

    var df = try createPivotTestData(allocator);
    defer df.deinit();

    // Try to pivot with string values column
    try testing.expectError(error.ValueColumnMustBeNumeric, reshape.pivot(&df, allocator, .{
        .index = "date",
        .columns = "sales", // Using sales (Int64) as columns
        .values = "region", // Using region (String) as values - should fail
        .aggfunc = .Sum,
    }));
}

test "pivot: memory leak test (1000 iterations)" {
    const allocator = testing.allocator;

    var i: u32 = 0;
    while (i < 1000) : (i += 1) {
        var df = try createPivotTestData(allocator);

        var pivoted = try reshape.pivot(&df, allocator, .{
            .index = "date",
            .columns = "region",
            .values = "sales",
            .aggfunc = .Sum,
        });

        pivoted.deinit();
        df.deinit();
    }

    // testing.allocator will report leaks automatically
}

test "pivot: large dataset (10K rows)" {
    const allocator = testing.allocator;

    // Create 10K rows with repeating pattern
    const row_count: u32 = 10_000;
    const columns = [_]ColumnDesc{
        ColumnDesc.init("id", .Int64, 0),
        ColumnDesc.init("category", .String, 1),
        ColumnDesc.init("value", .Float64, 2),
    };

    var df = try DataFrame.create(allocator, &columns, row_count);
    defer df.deinit();

    // Fill with repeating pattern (100 ids × 10 categories × 10 repetitions)
    var row_idx: u32 = 0;
    while (row_idx < row_count) : (row_idx += 1) {
        df.columns[0].data.Int64[row_idx] = @as(i64, @intCast(row_idx % 100));

        const category_idx = (row_idx / 100) % 10;
        var category_buf: [8]u8 = undefined;
        const category_str = try std.fmt.bufPrint(&category_buf, "cat_{}", .{category_idx});
        try df.columns[1].appendString(allocator, category_str);

        df.columns[2].data.Float64[row_idx] = @as(f64, @floatFromInt(row_idx));
    }

    // Update DataFrame row count and series lengths
    df.row_count = row_count;
    df.columns[0].length = row_count;
    df.columns[2].length = row_count;

    const start = std.time.nanoTimestamp();

    var pivoted = try reshape.pivot(&df, allocator, .{
        .index = "id",
        .columns = "category",
        .values = "value",
        .aggfunc = .Sum,
    });
    defer pivoted.deinit();

    const end = std.time.nanoTimestamp();
    const duration_ms = @as(f64, @floatFromInt(end - start)) / 1_000_000.0;

    std.debug.print("\nPivot 10K rows: {d:.2}ms\n", .{duration_ms});

    // Should have 100 unique ids (rows), 11 columns (id + 10 categories)
    try testing.expectEqual(@as(u32, 100), pivoted.row_count);
    try testing.expectEqual(@as(usize, 11), pivoted.columns.len);

    // Target: < 100ms for 10K rows
    try testing.expect(duration_ms < 100.0);
}

// ============================================================================
// Melt (Unpivot) Tests
// ============================================================================

test "melt: basic wide to long transformation" {
    const allocator = testing.allocator;

    // Create wide format DataFrame
    const row_count: u32 = 2;
    const columns = [_]ColumnDesc{
        ColumnDesc.init("date", .Int64, 0),
        ColumnDesc.init("East", .Float64, 1),
        ColumnDesc.init("West", .Float64, 2),
    };

    var df = try DataFrame.create(allocator, &columns, row_count);
    defer df.deinit();

    // Fill data: date, East, West
    // 1, 100.0, 200.0
    // 2, 120.0, 180.0
    df.columns[0].data.Int64[0] = 1;
    df.columns[0].data.Int64[1] = 2;
    df.columns[1].data.Float64[0] = 100.0;
    df.columns[1].data.Float64[1] = 120.0;
    df.columns[2].data.Float64[0] = 200.0;
    df.columns[2].data.Float64[1] = 180.0;

    df.row_count = row_count;
    df.columns[0].length = row_count;
    df.columns[1].length = row_count;
    df.columns[2].length = row_count;

    // Melt: date is id_var, East/West become variable/value
    var melted = try reshape.melt(&df, allocator, .{
        .id_vars = &[_][]const u8{"date"},
        .value_vars = &[_][]const u8{ "East", "West" },
        .var_name = "region",
        .value_name = "sales",
    });
    defer melted.deinit();

    // Should have 4 rows (2 rows × 2 melted columns)
    try testing.expectEqual(@as(u32, 4), melted.row_count);
    try testing.expectEqual(@as(usize, 3), melted.columns.len); // date, region, sales

    // Verify column names
    try testing.expectEqualStrings("date", melted.columns[0].name);
    try testing.expectEqualStrings("region", melted.columns[1].name);
    try testing.expectEqualStrings("sales", melted.columns[2].name);

    // Verify data
    const dates = melted.columns[0].data.Int64;
    try testing.expectEqual(@as(i64, 1), dates[0]);
    try testing.expectEqual(@as(i64, 1), dates[1]);
    try testing.expectEqual(@as(i64, 2), dates[2]);
    try testing.expectEqual(@as(i64, 2), dates[3]);

    const regions = &melted.columns[1].data.String;
    try testing.expectEqualStrings("East", regions.get(0));
    try testing.expectEqualStrings("West", regions.get(1));
    try testing.expectEqualStrings("East", regions.get(2));
    try testing.expectEqualStrings("West", regions.get(3));

    const sales = melted.columns[2].data.Float64;
    try testing.expectEqual(@as(f64, 100.0), sales[0]);
    try testing.expectEqual(@as(f64, 200.0), sales[1]);
    try testing.expectEqual(@as(f64, 120.0), sales[2]);
    try testing.expectEqual(@as(f64, 180.0), sales[3]);
}

test "melt: auto-detect value_vars (melt all non-id columns)" {
    const allocator = testing.allocator;

    const row_count: u32 = 1;
    const columns = [_]ColumnDesc{
        ColumnDesc.init("id", .Int64, 0),
        ColumnDesc.init("col1", .Float64, 1),
        ColumnDesc.init("col2", .Float64, 2),
        ColumnDesc.init("col3", .Float64, 3),
    };

    var df = try DataFrame.create(allocator, &columns, row_count);
    defer df.deinit();

    df.columns[0].data.Int64[0] = 1;
    df.columns[1].data.Float64[0] = 10.0;
    df.columns[2].data.Float64[0] = 20.0;
    df.columns[3].data.Float64[0] = 30.0;

    df.row_count = row_count;
    df.columns[0].length = row_count;
    df.columns[1].length = row_count;
    df.columns[2].length = row_count;
    df.columns[3].length = row_count;

    // Don't specify value_vars - should melt all non-id columns
    var melted = try reshape.melt(&df, allocator, .{
        .id_vars = &[_][]const u8{"id"},
    });
    defer melted.deinit();

    // Should have 3 rows (1 row × 3 melted columns: col1, col2, col3)
    try testing.expectEqual(@as(u32, 3), melted.row_count);
}

test "melt: multiple id_vars preserved" {
    const allocator = testing.allocator;

    const row_count: u32 = 2;
    const columns = [_]ColumnDesc{
        ColumnDesc.init("year", .Int64, 0),
        ColumnDesc.init("month", .Int64, 1),
        ColumnDesc.init("value1", .Float64, 2),
        ColumnDesc.init("value2", .Float64, 3),
    };

    var df = try DataFrame.create(allocator, &columns, row_count);
    defer df.deinit();

    df.columns[0].data.Int64[0] = 2024;
    df.columns[0].data.Int64[1] = 2024;
    df.columns[1].data.Int64[0] = 1;
    df.columns[1].data.Int64[1] = 2;
    df.columns[2].data.Float64[0] = 100.0;
    df.columns[2].data.Float64[1] = 150.0;
    df.columns[3].data.Float64[0] = 200.0;
    df.columns[3].data.Float64[1] = 250.0;

    df.row_count = row_count;
    df.columns[0].length = row_count;
    df.columns[1].length = row_count;
    df.columns[2].length = row_count;
    df.columns[3].length = row_count;

    var melted = try reshape.melt(&df, allocator, .{
        .id_vars = &[_][]const u8{ "year", "month" },
        .value_vars = &[_][]const u8{ "value1", "value2" },
    });
    defer melted.deinit();

    // Should have 4 rows (2 rows × 2 melted columns)
    try testing.expectEqual(@as(u32, 4), melted.row_count);
    try testing.expectEqual(@as(usize, 4), melted.columns.len); // year, month, variable, value

    // Verify both id columns preserved
    const years = melted.columns[0].data.Int64;
    try testing.expectEqual(@as(i64, 2024), years[0]);
    try testing.expectEqual(@as(i64, 2024), years[1]);

    const months = melted.columns[1].data.Int64;
    try testing.expectEqual(@as(i64, 1), months[0]);
    try testing.expectEqual(@as(i64, 1), months[1]);
    try testing.expectEqual(@as(i64, 2), months[2]);
    try testing.expectEqual(@as(i64, 2), months[3]);
}

test "melt: custom var_name and value_name" {
    const allocator = testing.allocator;

    const row_count: u32 = 1;
    const columns = [_]ColumnDesc{
        ColumnDesc.init("id", .Int64, 0),
        ColumnDesc.init("A", .Float64, 1),
        ColumnDesc.init("B", .Float64, 2),
    };

    var df = try DataFrame.create(allocator, &columns, row_count);
    defer df.deinit();

    df.columns[0].data.Int64[0] = 1;
    df.columns[1].data.Float64[0] = 10.0;
    df.columns[2].data.Float64[0] = 20.0;

    df.row_count = row_count;
    df.columns[0].length = row_count;
    df.columns[1].length = row_count;
    df.columns[2].length = row_count;

    var melted = try reshape.melt(&df, allocator, .{
        .id_vars = &[_][]const u8{"id"},
        .var_name = "metric",
        .value_name = "measurement",
    });
    defer melted.deinit();

    // Verify custom column names
    try testing.expectEqualStrings("metric", melted.columns[1].name);
    try testing.expectEqualStrings("measurement", melted.columns[2].name);
}

test "melt: single column to melt" {
    const allocator = testing.allocator;

    const row_count: u32 = 3;
    const columns = [_]ColumnDesc{
        ColumnDesc.init("id", .Int64, 0),
        ColumnDesc.init("value", .Float64, 1),
    };

    var df = try DataFrame.create(allocator, &columns, row_count);
    defer df.deinit();

    df.columns[0].data.Int64[0] = 1;
    df.columns[0].data.Int64[1] = 2;
    df.columns[0].data.Int64[2] = 3;
    df.columns[1].data.Float64[0] = 100.0;
    df.columns[1].data.Float64[1] = 200.0;
    df.columns[1].data.Float64[2] = 300.0;

    df.row_count = row_count;
    df.columns[0].length = row_count;
    df.columns[1].length = row_count;

    var melted = try reshape.melt(&df, allocator, .{
        .id_vars = &[_][]const u8{"id"},
    });
    defer melted.deinit();

    // Should have 3 rows (3 rows × 1 melted column)
    try testing.expectEqual(@as(u32, 3), melted.row_count);
}

test "melt: Float64 id_var preserved correctly" {
    const allocator = testing.allocator;

    const row_count: u32 = 2;
    const columns = [_]ColumnDesc{
        ColumnDesc.init("timestamp", .Float64, 0),
        ColumnDesc.init("value1", .Float64, 1),
        ColumnDesc.init("value2", .Float64, 2),
    };

    var df = try DataFrame.create(allocator, &columns, row_count);
    defer df.deinit();

    df.columns[0].data.Float64[0] = 1.5;
    df.columns[0].data.Float64[1] = 2.5;
    df.columns[1].data.Float64[0] = 10.0;
    df.columns[1].data.Float64[1] = 20.0;
    df.columns[2].data.Float64[0] = 30.0;
    df.columns[2].data.Float64[1] = 40.0;

    df.row_count = row_count;
    df.columns[0].length = row_count;
    df.columns[1].length = row_count;
    df.columns[2].length = row_count;

    var melted = try reshape.melt(&df, allocator, .{
        .id_vars = &[_][]const u8{"timestamp"},
    });
    defer melted.deinit();

    // Verify Float64 id column preserved
    const timestamps = melted.columns[0].data.Float64;
    try testing.expectEqual(@as(f64, 1.5), timestamps[0]);
    try testing.expectEqual(@as(f64, 1.5), timestamps[1]);
    try testing.expectEqual(@as(f64, 2.5), timestamps[2]);
    try testing.expectEqual(@as(f64, 2.5), timestamps[3]);
}

test "melt: Int64 values converted to Float64" {
    const allocator = testing.allocator;

    const row_count: u32 = 1;
    const columns = [_]ColumnDesc{
        ColumnDesc.init("id", .Int64, 0),
        ColumnDesc.init("count", .Int64, 1),
    };

    var df = try DataFrame.create(allocator, &columns, row_count);
    defer df.deinit();

    df.columns[0].data.Int64[0] = 1;
    df.columns[1].data.Int64[0] = 42;

    df.row_count = row_count;
    df.columns[0].length = row_count;
    df.columns[1].length = row_count;

    var melted = try reshape.melt(&df, allocator, .{
        .id_vars = &[_][]const u8{"id"},
    });
    defer melted.deinit();

    // Int64 value should be converted to Float64
    const values = melted.columns[2].data.Float64;
    try testing.expectEqual(@as(f64, 42.0), values[0]);
}

test "melt: error on invalid column name" {
    const allocator = testing.allocator;

    const row_count: u32 = 1;
    const columns = [_]ColumnDesc{
        ColumnDesc.init("id", .Int64, 0),
        ColumnDesc.init("value", .Float64, 1),
    };

    var df = try DataFrame.create(allocator, &columns, row_count);
    defer df.deinit();

    df.columns[0].data.Int64[0] = 1;
    df.columns[1].data.Float64[0] = 10.0;

    df.row_count = row_count;
    df.columns[0].length = row_count;
    df.columns[1].length = row_count;

    // Try to melt non-existent column
    const result = reshape.melt(&df, allocator, .{
        .id_vars = &[_][]const u8{"nonexistent"},
    });

    try testing.expectError(error.ColumnNotFound, result);
}

test "melt: no columns to melt error" {
    const allocator = testing.allocator;

    const row_count: u32 = 1;
    const columns = [_]ColumnDesc{
        ColumnDesc.init("id", .Int64, 0),
    };

    var df = try DataFrame.create(allocator, &columns, row_count);
    defer df.deinit();

    df.columns[0].data.Int64[0] = 1;

    df.row_count = row_count;
    df.columns[0].length = row_count;

    // All columns are id_vars - nothing to melt
    const result = reshape.melt(&df, allocator, .{
        .id_vars = &[_][]const u8{"id"},
    });

    try testing.expectError(error.NoColumnsToMelt, result);
}

test "melt: memory leak test (1000 iterations)" {
    const allocator = testing.allocator;

    var i: usize = 0;
    while (i < 1000) : (i += 1) {
        const row_count: u32 = 2;
        const columns = [_]ColumnDesc{
            ColumnDesc.init("id", .Int64, 0),
            ColumnDesc.init("A", .Float64, 1),
            ColumnDesc.init("B", .Float64, 2),
        };

        var df = try DataFrame.create(allocator, &columns, row_count);
        defer df.deinit();

        df.columns[0].data.Int64[0] = 1;
        df.columns[0].data.Int64[1] = 2;
        df.columns[1].data.Float64[0] = 10.0;
        df.columns[1].data.Float64[1] = 20.0;
        df.columns[2].data.Float64[0] = 30.0;
        df.columns[2].data.Float64[1] = 40.0;

        df.row_count = row_count;
        df.columns[0].length = row_count;
        df.columns[1].length = row_count;
        df.columns[2].length = row_count;

        var melted = try reshape.melt(&df, allocator, .{
            .id_vars = &[_][]const u8{"id"},
        });
        defer melted.deinit();
    }

    // testing.allocator will report leaks automatically
}

test "melt: large dataset (100 rows × 5 columns)" {
    const allocator = testing.allocator;

    const row_count: u32 = 100;
    const columns = [_]ColumnDesc{
        ColumnDesc.init("id", .Int64, 0),
        ColumnDesc.init("A", .Float64, 1),
        ColumnDesc.init("B", .Float64, 2),
        ColumnDesc.init("C", .Float64, 3),
        ColumnDesc.init("D", .Float64, 4),
    };

    var df = try DataFrame.create(allocator, &columns, row_count);
    defer df.deinit();

    // Fill data
    var row: u32 = 0;
    while (row < row_count) : (row += 1) {
        df.columns[0].data.Int64[row] = @intCast(row);
        df.columns[1].data.Float64[row] = @as(f64, @floatFromInt(row)) * 1.0;
        df.columns[2].data.Float64[row] = @as(f64, @floatFromInt(row)) * 2.0;
        df.columns[3].data.Float64[row] = @as(f64, @floatFromInt(row)) * 3.0;
        df.columns[4].data.Float64[row] = @as(f64, @floatFromInt(row)) * 4.0;
    }

    df.row_count = row_count;
    df.columns[0].length = row_count;
    df.columns[1].length = row_count;
    df.columns[2].length = row_count;
    df.columns[3].length = row_count;
    df.columns[4].length = row_count;

    var melted = try reshape.melt(&df, allocator, .{
        .id_vars = &[_][]const u8{"id"},
    });
    defer melted.deinit();

    // Should have 400 rows (100 rows × 4 melted columns)
    try testing.expectEqual(@as(u32, 400), melted.row_count);
}

test "melt → pivot round-trip" {
    const allocator = testing.allocator;

    // Start with wide format
    const row_count: u32 = 3;
    const columns = [_]ColumnDesc{
        ColumnDesc.init("date", .Int64, 0),
        ColumnDesc.init("East", .Float64, 1),
        ColumnDesc.init("West", .Float64, 2),
    };

    var original = try DataFrame.create(allocator, &columns, row_count);
    defer original.deinit();

    original.columns[0].data.Int64[0] = 1;
    original.columns[0].data.Int64[1] = 2;
    original.columns[0].data.Int64[2] = 3;
    original.columns[1].data.Float64[0] = 100.0;
    original.columns[1].data.Float64[1] = 120.0;
    original.columns[1].data.Float64[2] = 110.0;
    original.columns[2].data.Float64[0] = 200.0;
    original.columns[2].data.Float64[1] = 180.0;
    original.columns[2].data.Float64[2] = 190.0;

    original.row_count = row_count;
    original.columns[0].length = row_count;
    original.columns[1].length = row_count;
    original.columns[2].length = row_count;

    // Melt to long format
    var melted = try reshape.melt(&original, allocator, .{
        .id_vars = &[_][]const u8{"date"},
        .var_name = "region",
        .value_name = "sales",
    });
    defer melted.deinit();

    // Should have 6 rows (3 rows × 2 columns)
    try testing.expectEqual(@as(u32, 6), melted.row_count);

    // Pivot back to wide format
    var pivoted = try reshape.pivot(&melted, allocator, .{
        .index = "date",
        .columns = "region",
        .values = "sales",
        .aggfunc = .Sum,
    });
    defer pivoted.deinit();

    // Should match original dimensions
    try testing.expectEqual(@as(u32, 3), pivoted.row_count);
    try testing.expectEqual(@as(usize, 3), pivoted.columns.len); // date + East + West

    // Verify column names (order may differ)
    try testing.expectEqualStrings("date", pivoted.columns[0].name);
    // East and West columns should exist (order may vary)
}

// ============================================================================
// Transpose Tests
// ============================================================================

// Helper: Create small numeric DataFrame for transpose testing
fn createTransposeTestData(allocator: std.mem.Allocator) !DataFrame {
    // Create 3×3 matrix:
    //     A   B   C
    // 0   1   2   3
    // 1   4   5   6
    // 2   7   8   9

    const row_count: u32 = 3;
    const columns = [_]ColumnDesc{
        ColumnDesc.init("A", .Int64, 0),
        ColumnDesc.init("B", .Int64, 1),
        ColumnDesc.init("C", .Int64, 2),
    };

    var df = try DataFrame.create(allocator, &columns, row_count);

    // Fill column A: [1, 4, 7]
    df.columns[0].data.Int64[0] = 1;
    df.columns[0].data.Int64[1] = 4;
    df.columns[0].data.Int64[2] = 7;

    // Fill column B: [2, 5, 8]
    df.columns[1].data.Int64[0] = 2;
    df.columns[1].data.Int64[1] = 5;
    df.columns[1].data.Int64[2] = 8;

    // Fill column C: [3, 6, 9]
    df.columns[2].data.Int64[0] = 3;
    df.columns[2].data.Int64[1] = 6;
    df.columns[2].data.Int64[2] = 9;

    df.row_count = row_count;
    df.columns[0].length = row_count;
    df.columns[1].length = row_count;
    df.columns[2].length = row_count;

    return df;
}

test "transpose: basic 3x3 matrix" {
    const allocator = testing.allocator;

    var df = try createTransposeTestData(allocator);
    defer df.deinit();

    var transposed = try reshape.transpose(&df, allocator);
    defer transposed.deinit();

    // Verify dimensions swapped: 3 rows × 3 cols → 3 rows × 3 cols
    try testing.expectEqual(@as(u32, 3), transposed.row_count);
    try testing.expectEqual(@as(usize, 3), transposed.columns.len);

    // Verify column names: row_0, row_1, row_2
    try testing.expectEqualStrings("row_0", transposed.columns[0].name);
    try testing.expectEqualStrings("row_1", transposed.columns[1].name);
    try testing.expectEqualStrings("row_2", transposed.columns[2].name);

    // Verify transposed data (all Float64 after transpose)
    // Original column A [1, 4, 7] becomes row 0 in transposed
    try testing.expectEqual(@as(f64, 1.0), transposed.columns[0].data.Float64[0]); // A at row 0
    try testing.expectEqual(@as(f64, 4.0), transposed.columns[1].data.Float64[0]); // A at row 1
    try testing.expectEqual(@as(f64, 7.0), transposed.columns[2].data.Float64[0]); // A at row 2

    // Original column B [2, 5, 8] becomes row 1 in transposed
    try testing.expectEqual(@as(f64, 2.0), transposed.columns[0].data.Float64[1]); // B at row 0
    try testing.expectEqual(@as(f64, 5.0), transposed.columns[1].data.Float64[1]); // B at row 1
    try testing.expectEqual(@as(f64, 8.0), transposed.columns[2].data.Float64[1]); // B at row 2

    // Original column C [3, 6, 9] becomes row 2 in transposed
    try testing.expectEqual(@as(f64, 3.0), transposed.columns[0].data.Float64[2]); // C at row 0
    try testing.expectEqual(@as(f64, 6.0), transposed.columns[1].data.Float64[2]); // C at row 1
    try testing.expectEqual(@as(f64, 9.0), transposed.columns[2].data.Float64[2]); // C at row 2
}

test "transpose: single row DataFrame" {
    const allocator = testing.allocator;

    const row_count: u32 = 1;
    const columns = [_]ColumnDesc{
        ColumnDesc.init("A", .Int64, 0),
        ColumnDesc.init("B", .Int64, 1),
        ColumnDesc.init("C", .Int64, 2),
    };

    var df = try DataFrame.create(allocator, &columns, row_count);
    defer df.deinit();

    df.columns[0].data.Int64[0] = 10;
    df.columns[1].data.Int64[0] = 20;
    df.columns[2].data.Int64[0] = 30;
    df.row_count = row_count;
    df.columns[0].length = row_count;
    df.columns[1].length = row_count;
    df.columns[2].length = row_count;

    var transposed = try reshape.transpose(&df, allocator);
    defer transposed.deinit();

    // 1 row × 3 cols → 3 rows × 1 col
    try testing.expectEqual(@as(u32, 3), transposed.row_count);
    try testing.expectEqual(@as(usize, 1), transposed.columns.len);

    // Column is named row_0 (from the single source row)
    try testing.expectEqualStrings("row_0", transposed.columns[0].name);

    // Values: [10, 20, 30] (from columns A, B, C)
    try testing.expectEqual(@as(f64, 10.0), transposed.columns[0].data.Float64[0]);
    try testing.expectEqual(@as(f64, 20.0), transposed.columns[0].data.Float64[1]);
    try testing.expectEqual(@as(f64, 30.0), transposed.columns[0].data.Float64[2]);
}

test "transpose: single column DataFrame" {
    const allocator = testing.allocator;

    const row_count: u32 = 5;
    const columns = [_]ColumnDesc{
        ColumnDesc.init("values", .Int64, 0),
    };

    var df = try DataFrame.create(allocator, &columns, row_count);
    defer df.deinit();

    df.columns[0].data.Int64[0] = 1;
    df.columns[0].data.Int64[1] = 2;
    df.columns[0].data.Int64[2] = 3;
    df.columns[0].data.Int64[3] = 4;
    df.columns[0].data.Int64[4] = 5;
    df.row_count = row_count;
    df.columns[0].length = row_count;

    var transposed = try reshape.transpose(&df, allocator);
    defer transposed.deinit();

    // 5 rows × 1 col → 1 row × 5 cols
    try testing.expectEqual(@as(u32, 1), transposed.row_count);
    try testing.expectEqual(@as(usize, 5), transposed.columns.len);

    // Column names: row_0, row_1, row_2, row_3, row_4
    try testing.expectEqualStrings("row_0", transposed.columns[0].name);
    try testing.expectEqualStrings("row_4", transposed.columns[4].name);

    // All values in single row
    try testing.expectEqual(@as(f64, 1.0), transposed.columns[0].data.Float64[0]);
    try testing.expectEqual(@as(f64, 2.0), transposed.columns[1].data.Float64[0]);
    try testing.expectEqual(@as(f64, 3.0), transposed.columns[2].data.Float64[0]);
    try testing.expectEqual(@as(f64, 4.0), transposed.columns[3].data.Float64[0]);
    try testing.expectEqual(@as(f64, 5.0), transposed.columns[4].data.Float64[0]);
}

test "transpose: mixed Int64 and Float64 types" {
    const allocator = testing.allocator;

    const row_count: u32 = 2;
    const columns = [_]ColumnDesc{
        ColumnDesc.init("int_col", .Int64, 0),
        ColumnDesc.init("float_col", .Float64, 1),
    };

    var df = try DataFrame.create(allocator, &columns, row_count);
    defer df.deinit();

    df.columns[0].data.Int64[0] = 10;
    df.columns[0].data.Int64[1] = 20;
    df.columns[1].data.Float64[0] = 1.5;
    df.columns[1].data.Float64[1] = 2.5;
    df.row_count = row_count;
    df.columns[0].length = row_count;
    df.columns[1].length = row_count;

    var transposed = try reshape.transpose(&df, allocator);
    defer transposed.deinit();

    // 2 rows × 2 cols → 2 rows × 2 cols
    try testing.expectEqual(@as(u32, 2), transposed.row_count);
    try testing.expectEqual(@as(usize, 2), transposed.columns.len);

    // All converted to Float64
    try testing.expectEqual(ValueType.Float64, transposed.columns[0].value_type);
    try testing.expectEqual(ValueType.Float64, transposed.columns[1].value_type);

    // Verify conversions: Int64 → Float64
    try testing.expectEqual(@as(f64, 10.0), transposed.columns[0].data.Float64[0]);
    try testing.expectEqual(@as(f64, 20.0), transposed.columns[1].data.Float64[0]);
    try testing.expectEqual(@as(f64, 1.5), transposed.columns[0].data.Float64[1]);
    try testing.expectEqual(@as(f64, 2.5), transposed.columns[1].data.Float64[1]);
}

test "transpose: double transpose returns original dimensions" {
    const allocator = testing.allocator;

    var original = try createTransposeTestData(allocator);
    defer original.deinit();

    var once_transposed = try reshape.transpose(&original, allocator);
    defer once_transposed.deinit();

    // Verify first transpose worked
    try testing.expectEqual(@as(u32, 3), once_transposed.row_count);
    try testing.expectEqual(@as(usize, 3), once_transposed.columns.len);

    var twice_transposed = try reshape.transpose(&once_transposed, allocator);
    defer twice_transposed.deinit();

    // Dimensions should match original
    try testing.expectEqual(original.row_count, twice_transposed.row_count);
    try testing.expectEqual(original.columns.len, twice_transposed.columns.len);

    // Values should match (accounting for Int64 → Float64 conversion)
    const original_a = original.columns[0].data.Int64;
    const result_a = twice_transposed.columns[0].data.Float64;

    try testing.expectEqual(@as(f64, @floatFromInt(original_a[0])), result_a[0]);
    try testing.expectEqual(@as(f64, @floatFromInt(original_a[1])), result_a[1]);
    try testing.expectEqual(@as(f64, @floatFromInt(original_a[2])), result_a[2]);
}

test "transpose: rectangular matrix (more rows than columns)" {
    const allocator = testing.allocator;

    const row_count: u32 = 5;
    const columns = [_]ColumnDesc{
        ColumnDesc.init("X", .Int64, 0),
        ColumnDesc.init("Y", .Int64, 1),
    };

    var df = try DataFrame.create(allocator, &columns, row_count);
    defer df.deinit();

    df.columns[0].data.Int64[0] = 1;
    df.columns[0].data.Int64[1] = 2;
    df.columns[0].data.Int64[2] = 3;
    df.columns[0].data.Int64[3] = 4;
    df.columns[0].data.Int64[4] = 5;

    df.columns[1].data.Int64[0] = 10;
    df.columns[1].data.Int64[1] = 20;
    df.columns[1].data.Int64[2] = 30;
    df.columns[1].data.Int64[3] = 40;
    df.columns[1].data.Int64[4] = 50;

    df.row_count = row_count;
    df.columns[0].length = row_count;
    df.columns[1].length = row_count;

    var transposed = try reshape.transpose(&df, allocator);
    defer transposed.deinit();

    // 5 rows × 2 cols → 2 rows × 5 cols
    try testing.expectEqual(@as(u32, 2), transposed.row_count);
    try testing.expectEqual(@as(usize, 5), transposed.columns.len);

    // First row (was column X): [1, 2, 3, 4, 5]
    try testing.expectEqual(@as(f64, 1.0), transposed.columns[0].data.Float64[0]);
    try testing.expectEqual(@as(f64, 2.0), transposed.columns[1].data.Float64[0]);
    try testing.expectEqual(@as(f64, 3.0), transposed.columns[2].data.Float64[0]);

    // Second row (was column Y): [10, 20, 30, 40, 50]
    try testing.expectEqual(@as(f64, 10.0), transposed.columns[0].data.Float64[1]);
    try testing.expectEqual(@as(f64, 20.0), transposed.columns[1].data.Float64[1]);
    try testing.expectEqual(@as(f64, 50.0), transposed.columns[4].data.Float64[1]);
}

test "transpose: rectangular matrix (more columns than rows)" {
    const allocator = testing.allocator;

    const row_count: u32 = 2;
    const columns = [_]ColumnDesc{
        ColumnDesc.init("A", .Int64, 0),
        ColumnDesc.init("B", .Int64, 1),
        ColumnDesc.init("C", .Int64, 2),
        ColumnDesc.init("D", .Int64, 3),
    };

    var df = try DataFrame.create(allocator, &columns, row_count);
    defer df.deinit();

    df.columns[0].data.Int64[0] = 1;
    df.columns[0].data.Int64[1] = 5;
    df.columns[1].data.Int64[0] = 2;
    df.columns[1].data.Int64[1] = 6;
    df.columns[2].data.Int64[0] = 3;
    df.columns[2].data.Int64[1] = 7;
    df.columns[3].data.Int64[0] = 4;
    df.columns[3].data.Int64[1] = 8;

    df.row_count = row_count;
    var i: usize = 0;
    while (i < 4) : (i += 1) {
        df.columns[i].length = row_count;
    }

    var transposed = try reshape.transpose(&df, allocator);
    defer transposed.deinit();

    // 2 rows × 4 cols → 4 rows × 2 cols
    try testing.expectEqual(@as(u32, 4), transposed.row_count);
    try testing.expectEqual(@as(usize, 2), transposed.columns.len);

    // Column row_0: [1, 2, 3, 4] (from first row)
    try testing.expectEqual(@as(f64, 1.0), transposed.columns[0].data.Float64[0]);
    try testing.expectEqual(@as(f64, 2.0), transposed.columns[0].data.Float64[1]);
    try testing.expectEqual(@as(f64, 3.0), transposed.columns[0].data.Float64[2]);
    try testing.expectEqual(@as(f64, 4.0), transposed.columns[0].data.Float64[3]);

    // Column row_1: [5, 6, 7, 8] (from second row)
    try testing.expectEqual(@as(f64, 5.0), transposed.columns[1].data.Float64[0]);
    try testing.expectEqual(@as(f64, 6.0), transposed.columns[1].data.Float64[1]);
    try testing.expectEqual(@as(f64, 7.0), transposed.columns[1].data.Float64[2]);
    try testing.expectEqual(@as(f64, 8.0), transposed.columns[1].data.Float64[3]);
}

test "transpose: with Bool columns" {
    const allocator = testing.allocator;

    const row_count: u32 = 3;
    const columns = [_]ColumnDesc{
        ColumnDesc.init("flag1", .Bool, 0),
        ColumnDesc.init("flag2", .Bool, 1),
    };

    var df = try DataFrame.create(allocator, &columns, row_count);
    defer df.deinit();

    df.columns[0].data.Bool[0] = true;
    df.columns[0].data.Bool[1] = false;
    df.columns[0].data.Bool[2] = true;
    df.columns[1].data.Bool[0] = false;
    df.columns[1].data.Bool[1] = true;
    df.columns[1].data.Bool[2] = false;

    df.row_count = row_count;
    df.columns[0].length = row_count;
    df.columns[1].length = row_count;

    var transposed = try reshape.transpose(&df, allocator);
    defer transposed.deinit();

    // 3 rows × 2 cols → 2 rows × 3 cols
    try testing.expectEqual(@as(u32, 2), transposed.row_count);
    try testing.expectEqual(@as(usize, 3), transposed.columns.len);

    // Bool converted to Float64: true=1.0, false=0.0
    try testing.expectEqual(@as(f64, 1.0), transposed.columns[0].data.Float64[0]); // true
    try testing.expectEqual(@as(f64, 0.0), transposed.columns[1].data.Float64[0]); // false
    try testing.expectEqual(@as(f64, 1.0), transposed.columns[2].data.Float64[0]); // true

    try testing.expectEqual(@as(f64, 0.0), transposed.columns[0].data.Float64[1]); // false
    try testing.expectEqual(@as(f64, 1.0), transposed.columns[1].data.Float64[1]); // true
    try testing.expectEqual(@as(f64, 0.0), transposed.columns[2].data.Float64[1]); // false
}

test "transpose: memory leak test (1000 iterations)" {
    const allocator = testing.allocator;

    var iter: u32 = 0;
    while (iter < 1000) : (iter += 1) {
        var df = try createTransposeTestData(allocator);
        var transposed = try reshape.transpose(&df, allocator);
        transposed.deinit();
        df.deinit();
    }

    // testing.allocator will report leaks automatically
}

test "transpose: large dataset (100 rows × 100 columns)" {
    const allocator = testing.allocator;

    const row_count: u32 = 100;
    const col_count: u32 = 100;

    // Create column descriptors
    var columns = try allocator.alloc(ColumnDesc, col_count);
    defer allocator.free(columns);

    var col_idx: u32 = 0;
    while (col_idx < col_count) : (col_idx += 1) {
        const name = try std.fmt.allocPrint(allocator, "col_{d}", .{col_idx});
        columns[col_idx] = ColumnDesc{
            .name = name,
            .value_type = .Int64,
            .index = col_idx,
        };
    }

    var df = try DataFrame.create(allocator, columns, row_count);
    defer df.deinit();

    // Fill with sequential values
    col_idx = 0;
    while (col_idx < col_count) : (col_idx += 1) {
        var row_idx: u32 = 0;
        while (row_idx < row_count) : (row_idx += 1) {
            const value: i64 = @intCast(row_idx * 100 + col_idx);
            df.columns[col_idx].data.Int64[row_idx] = value;
        }
        df.columns[col_idx].length = row_count;
    }
    df.row_count = row_count;

    const start = std.time.nanoTimestamp();
    var transposed = try reshape.transpose(&df, allocator);
    const end = std.time.nanoTimestamp();
    defer transposed.deinit();

    const duration_ms = @as(f64, @floatFromInt(end - start)) / 1_000_000.0;
    // Performance: typically <5ms for 100×100
    _ = duration_ms; // Suppress unused variable warning

    // Verify dimensions
    try testing.expectEqual(@as(u32, 100), transposed.row_count);
    try testing.expectEqual(@as(usize, 100), transposed.columns.len);

    // Spot-check a few values
    // Original (0,0) = 0*100+0 = 0 → Transposed column[0][0] = 0
    try testing.expectEqual(@as(f64, 0.0), transposed.columns[0].data.Float64[0]);
    // Original (0,99) = 0*100+99 = 99 → Transposed column[0][99] = 99
    try testing.expectEqual(@as(f64, 99.0), transposed.columns[0].data.Float64[99]);
    // Original (99,0) = 99*100+0 = 9900 → Transposed column[99][0] = 9900
    try testing.expectEqual(@as(f64, 9900.0), transposed.columns[99].data.Float64[0]);
}

// ============================================================================
// Stack Tests
// ============================================================================

// Helper: Create test data for stack operations
fn createStackTestData(allocator: std.mem.Allocator) !DataFrame {
    // Create wide-format data:
    //   id    A    B    C
    //   1    10   20   30
    //   2    40   50   60

    const row_count: u32 = 2;
    const columns = [_]ColumnDesc{
        ColumnDesc.init("id", .Int64, 0),
        ColumnDesc.init("A", .Int64, 1),
        ColumnDesc.init("B", .Int64, 2),
        ColumnDesc.init("C", .Int64, 3),
    };

    var df = try DataFrame.create(allocator, &columns, row_count);

    // Fill id column
    df.columns[0].data.Int64[0] = 1;
    df.columns[0].data.Int64[1] = 2;

    // Fill A column
    df.columns[1].data.Int64[0] = 10;
    df.columns[1].data.Int64[1] = 40;

    // Fill B column
    df.columns[2].data.Int64[0] = 20;
    df.columns[2].data.Int64[1] = 50;

    // Fill C column
    df.columns[3].data.Int64[0] = 30;
    df.columns[3].data.Int64[1] = 60;

    df.row_count = row_count;
    df.columns[0].length = row_count;
    df.columns[1].length = row_count;
    df.columns[2].length = row_count;
    df.columns[3].length = row_count;

    return df;
}

test "stack: basic wide to long conversion" {
    const allocator = testing.allocator;

    var df = try createStackTestData(allocator);
    defer df.deinit();

    var stacked = try reshape.stack(&df, allocator, .{
        .id_column = "id",
        .var_name = "variable",
        .value_name = "value",
    });
    defer stacked.deinit();

    // 2 rows × 4 cols → 2 rows × 3 value cols = 6 rows × 3 cols
    try testing.expectEqual(@as(u32, 6), stacked.row_count);
    try testing.expectEqual(@as(usize, 3), stacked.columns.len);

    // Verify column names
    try testing.expectEqualStrings("id", stacked.column_descs[0].name);
    try testing.expectEqualStrings("variable", stacked.column_descs[1].name);
    try testing.expectEqualStrings("value", stacked.column_descs[2].name);

    // Verify first 3 rows (id=1, variables A/B/C)
    try testing.expectEqual(@as(i64, 1), stacked.columns[0].data.Int64[0]);
    try testing.expectEqual(@as(i64, 1), stacked.columns[0].data.Int64[1]);
    try testing.expectEqual(@as(i64, 1), stacked.columns[0].data.Int64[2]);

    // Verify values for id=1
    try testing.expectEqual(@as(f64, 10.0), stacked.columns[2].data.Float64[0]); // A
    try testing.expectEqual(@as(f64, 20.0), stacked.columns[2].data.Float64[1]); // B
    try testing.expectEqual(@as(f64, 30.0), stacked.columns[2].data.Float64[2]); // C

    // Verify last 3 rows (id=2, variables A/B/C)
    try testing.expectEqual(@as(i64, 2), stacked.columns[0].data.Int64[3]);
    try testing.expectEqual(@as(f64, 40.0), stacked.columns[2].data.Float64[3]); // A
    try testing.expectEqual(@as(f64, 50.0), stacked.columns[2].data.Float64[4]); // B
    try testing.expectEqual(@as(f64, 60.0), stacked.columns[2].data.Float64[5]); // C
}

test "stack: custom column names" {
    const allocator = testing.allocator;

    var df = try createStackTestData(allocator);
    defer df.deinit();

    var stacked = try reshape.stack(&df, allocator, .{
        .id_column = "id",
        .var_name = "metric",
        .value_name = "measurement",
    });
    defer stacked.deinit();

    // Verify custom column names
    try testing.expectEqualStrings("id", stacked.column_descs[0].name);
    try testing.expectEqualStrings("metric", stacked.column_descs[1].name);
    try testing.expectEqualStrings("measurement", stacked.column_descs[2].name);
}

test "stack: single row DataFrame" {
    const allocator = testing.allocator;

    const row_count: u32 = 1;
    const columns = [_]ColumnDesc{
        ColumnDesc.init("key", .Int64, 0),
        ColumnDesc.init("X", .Int64, 1),
        ColumnDesc.init("Y", .Int64, 2),
    };

    var df = try DataFrame.create(allocator, &columns, row_count);
    defer df.deinit();

    df.columns[0].data.Int64[0] = 100;
    df.columns[1].data.Int64[0] = 1;
    df.columns[2].data.Int64[0] = 2;
    df.row_count = row_count;
    df.columns[0].length = row_count;
    df.columns[1].length = row_count;
    df.columns[2].length = row_count;

    var stacked = try reshape.stack(&df, allocator, .{
        .id_column = "key",
    });
    defer stacked.deinit();

    // 1 row × 3 cols → 1 row × 2 value cols = 2 rows
    try testing.expectEqual(@as(u32, 2), stacked.row_count);

    // Both rows should have same id
    try testing.expectEqual(@as(i64, 100), stacked.columns[0].data.Int64[0]);
    try testing.expectEqual(@as(i64, 100), stacked.columns[0].data.Int64[1]);

    // Values should be X and Y
    try testing.expectEqual(@as(f64, 1.0), stacked.columns[2].data.Float64[0]);
    try testing.expectEqual(@as(f64, 2.0), stacked.columns[2].data.Float64[1]);
}

test "stack: Float64 id column" {
    const allocator = testing.allocator;

    const row_count: u32 = 2;
    const columns = [_]ColumnDesc{
        ColumnDesc.init("timestamp", .Float64, 0),
        ColumnDesc.init("temp", .Int64, 1),
        ColumnDesc.init("humidity", .Int64, 2),
    };

    var df = try DataFrame.create(allocator, &columns, row_count);
    defer df.deinit();

    df.columns[0].data.Float64[0] = 1.5;
    df.columns[0].data.Float64[1] = 2.5;
    df.columns[1].data.Int64[0] = 20;
    df.columns[1].data.Int64[1] = 25;
    df.columns[2].data.Int64[0] = 60;
    df.columns[2].data.Int64[1] = 65;
    df.row_count = row_count;
    df.columns[0].length = row_count;
    df.columns[1].length = row_count;
    df.columns[2].length = row_count;

    var stacked = try reshape.stack(&df, allocator, .{
        .id_column = "timestamp",
    });
    defer stacked.deinit();

    // Verify Float64 id values preserved
    try testing.expectEqual(@as(f64, 1.5), stacked.columns[0].data.Float64[0]);
    try testing.expectEqual(@as(f64, 1.5), stacked.columns[0].data.Float64[1]);
    try testing.expectEqual(@as(f64, 2.5), stacked.columns[0].data.Float64[2]);
    try testing.expectEqual(@as(f64, 2.5), stacked.columns[0].data.Float64[3]);
}

test "stack: error on missing id column" {
    const allocator = testing.allocator;

    var df = try createStackTestData(allocator);
    defer df.deinit();

    const result = reshape.stack(&df, allocator, .{
        .id_column = "nonexistent",
    });

    try testing.expectError(error.ColumnNotFound, result);
}

test "stack: memory leak test (1000 iterations)" {
    const allocator = testing.allocator;

    var iter: u32 = 0;
    while (iter < 1000) : (iter += 1) {
        var df = try createStackTestData(allocator);
        var stacked = try reshape.stack(&df, allocator, .{
            .id_column = "id",
        });
        stacked.deinit();
        df.deinit();
    }

    // testing.allocator will report leaks automatically
}

// ============================================================================
// Unstack Tests
// ============================================================================

// Helper: Create test data for unstack operations (long format)
fn createUnstackTestData(allocator: std.mem.Allocator) !DataFrame {
    // Create long-format data:
    //   id  variable  value
    //   1      A        10
    //   1      B        20
    //   1      C        30
    //   2      A        40
    //   2      B        50
    //   2      C        60

    const row_count: u32 = 6;
    const columns = [_]ColumnDesc{
        ColumnDesc.init("id", .Int64, 0),
        ColumnDesc.init("variable", .String, 1),
        ColumnDesc.init("value", .Int64, 2),
    };

    var df = try DataFrame.create(allocator, &columns, row_count);

    // Fill id column
    df.columns[0].data.Int64[0] = 1;
    df.columns[0].data.Int64[1] = 1;
    df.columns[0].data.Int64[2] = 1;
    df.columns[0].data.Int64[3] = 2;
    df.columns[0].data.Int64[4] = 2;
    df.columns[0].data.Int64[5] = 2;

    // Fill variable column
    try df.columns[1].appendString(allocator, "A");
    try df.columns[1].appendString(allocator, "B");
    try df.columns[1].appendString(allocator, "C");
    try df.columns[1].appendString(allocator, "A");
    try df.columns[1].appendString(allocator, "B");
    try df.columns[1].appendString(allocator, "C");

    // Fill value column
    df.columns[2].data.Int64[0] = 10;
    df.columns[2].data.Int64[1] = 20;
    df.columns[2].data.Int64[2] = 30;
    df.columns[2].data.Int64[3] = 40;
    df.columns[2].data.Int64[4] = 50;
    df.columns[2].data.Int64[5] = 60;

    df.row_count = row_count;
    df.columns[0].length = row_count;
    df.columns[2].length = row_count;

    return df;
}

test "unstack: basic long to wide conversion" {
    const allocator = testing.allocator;

    var df = try createUnstackTestData(allocator);
    defer df.deinit();

    var unstacked = try reshape.unstack(&df, allocator, .{
        .index = "id",
        .columns = "variable",
        .values = "value",
    });
    defer unstacked.deinit();

    // 6 rows × 3 cols → 2 rows × 4 cols (id + A + B + C)
    try testing.expectEqual(@as(u32, 2), unstacked.row_count);
    try testing.expectEqual(@as(usize, 4), unstacked.columns.len);

    // Verify id column
    try testing.expectEqualStrings("id", unstacked.column_descs[0].name);
    try testing.expectEqual(@as(i64, 1), unstacked.columns[0].data.Int64[0]);
    try testing.expectEqual(@as(i64, 2), unstacked.columns[0].data.Int64[1]);

    // Note: Column order for A/B/C may vary due to hash map ordering
    // Just verify all values exist somewhere in the result
    var found_values = [_]bool{false} ** 6;

    var col_idx: usize = 1;
    while (col_idx < unstacked.columns.len) : (col_idx += 1) {
        const values = unstacked.columns[col_idx].data.Float64;

        // Check for expected values
        if (values[0] == 10.0) found_values[0] = true;
        if (values[0] == 20.0) found_values[1] = true;
        if (values[0] == 30.0) found_values[2] = true;
        if (values[1] == 40.0) found_values[3] = true;
        if (values[1] == 50.0) found_values[4] = true;
        if (values[1] == 60.0) found_values[5] = true;
    }

    // All values should be found
    for (found_values) |found| {
        try testing.expect(found);
    }
}

test "unstack: round-trip with stack" {
    const allocator = testing.allocator;

    var original = try createStackTestData(allocator);
    defer original.deinit();

    // Stack: wide → long
    var stacked = try reshape.stack(&original, allocator, .{
        .id_column = "id",
        .var_name = "variable",
        .value_name = "value",
    });
    defer stacked.deinit();

    // Unstack: long → wide
    var unstacked = try reshape.unstack(&stacked, allocator, .{
        .index = "id",
        .columns = "variable",
        .values = "value",
    });
    defer unstacked.deinit();

    // Should have same dimensions as original
    try testing.expectEqual(original.row_count, unstacked.row_count);
    try testing.expectEqual(original.columns.len, unstacked.columns.len);
}

test "unstack: single unique id" {
    const allocator = testing.allocator;

    const row_count: u32 = 3;
    const columns = [_]ColumnDesc{
        ColumnDesc.init("key", .Int64, 0),
        ColumnDesc.init("metric", .String, 1),
        ColumnDesc.init("val", .Int64, 2),
    };

    var df = try DataFrame.create(allocator, &columns, row_count);
    defer df.deinit();

    // All rows have same id
    df.columns[0].data.Int64[0] = 1;
    df.columns[0].data.Int64[1] = 1;
    df.columns[0].data.Int64[2] = 1;

    try df.columns[1].appendString(allocator, "X");
    try df.columns[1].appendString(allocator, "Y");
    try df.columns[1].appendString(allocator, "Z");

    df.columns[2].data.Int64[0] = 100;
    df.columns[2].data.Int64[1] = 200;
    df.columns[2].data.Int64[2] = 300;

    df.row_count = row_count;
    df.columns[0].length = row_count;
    df.columns[2].length = row_count;

    var unstacked = try reshape.unstack(&df, allocator, .{
        .index = "key",
        .columns = "metric",
        .values = "val",
    });
    defer unstacked.deinit();

    // Should result in 1 row with 4 columns (key + X + Y + Z)
    try testing.expectEqual(@as(u32, 1), unstacked.row_count);
    try testing.expectEqual(@as(usize, 4), unstacked.columns.len);

    // Verify id
    try testing.expectEqual(@as(i64, 1), unstacked.columns[0].data.Int64[0]);
}

test "unstack: memory leak test (1000 iterations)" {
    const allocator = testing.allocator;

    var iter: u32 = 0;
    while (iter < 1000) : (iter += 1) {
        var df = try createUnstackTestData(allocator);
        var unstacked = try reshape.unstack(&df, allocator, .{
            .index = "id",
            .columns = "variable",
            .values = "value",
        });
        unstacked.deinit();
        df.deinit();
    }

    // testing.allocator will report leaks automatically
}

test "stack and unstack: comprehensive round-trip test" {
    const allocator = testing.allocator;

    // Start with wide format
    var wide = try createStackTestData(allocator);
    defer wide.deinit();

    const original_rows = wide.row_count;
    const original_cols = wide.columns.len;

    // Wide → Long (stack)
    var long = try reshape.stack(&wide, allocator, .{
        .id_column = "id",
        .var_name = "variable",
        .value_name = "value",
    });
    defer long.deinit();

    // Verify long format dimensions
    const expected_long_rows = original_rows * (original_cols - 1); // id column not stacked
    try testing.expectEqual(expected_long_rows, long.row_count);
    try testing.expectEqual(@as(usize, 3), long.columns.len); // id, variable, value

    // Long → Wide (unstack)
    var wide_again = try reshape.unstack(&long, allocator, .{
        .index = "id",
        .columns = "variable",
        .values = "value",
    });
    defer wide_again.deinit();

    // Verify dimensions match original
    try testing.expectEqual(original_rows, wide_again.row_count);
    try testing.expectEqual(original_cols, wide_again.columns.len);
}
