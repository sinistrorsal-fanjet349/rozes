# Rozes Source Code - Implementation Guide

**Purpose**: Implementation patterns, code organization, and Zig-specific guidelines for the Rozes source code.

---

## Table of Contents

1. [Critical WebAssembly Pitfalls](#critical-webassembly-pitfalls) ‚ö†Ô∏è **READ THIS FIRST**
2. [Performance Optimization Strategy](#performance-optimization-strategy) üöÄ **NEW**
3. [Tiger Style Learnings from String Column Implementation](#tiger-style-learnings-from-string-column-implementation) üéØ
4. [Source Organization](#source-organization)
5. [Zig Implementation Patterns](#zig-implementation-patterns)
6. [Tiger Style Enforcement](#tiger-style-enforcement)
7. [Common Code Patterns](#common-code-patterns)
8. [Error Handling](#error-handling)
9. [Memory Management](#memory-management)
10. [Testing Patterns](#testing-patterns)

---

## Performance Optimization Strategy

> **üöÄ NEW (2025-10-28)**: Comprehensive optimization approach based on successful join optimization (593ms ‚Üí 16ms, 97.3% improvement).

### Quick Reference

**For detailed optimization methodology, see: [`../docs/OPTIMIZATION_APPROACH.md`](../docs/OPTIMIZATION_APPROACH.md)**

### Core Principles (TL;DR)

1. **Profile First, Optimize Second**

   - Always measure before optimizing
   - Don't guess bottlenecks - use profiling tools
   - Example: Join optimization revealed data copying (40-60% of time), NOT hash operations

2. **Low-Hanging Fruit Priority**

   - ‚ë† Algorithmic improvements (biggest impact)
   - ‚ë° SIMD integration (2-5√ó speedup)
   - ‚ë¢ Memory layout (cache-friendly)
   - ‚ë£ Code elimination (remove redundant work)

3. **Measure Everything**
   - Baseline performance (before)
   - Expected improvement (calculation)
   - Actual improvement (benchmark)
   - Correctness (tests pass)

### Current Optimization Status (Phase 1)

| Operation   | Baseline   | Target   | Strategy        | Status               |
| ----------- | ---------- | -------- | --------------- | -------------------- |
| CSV Parse   | 555ms      | <550ms   | (Maintained)    | ‚úÖ                   |
| Filter      | 14ms       | <15ms    | (Maintained)    | ‚úÖ                   |
| **Sort**    | **6.73ms** | **<5ms** | **SIMD merge**  | ‚è∏Ô∏è **IN PROGRESS**   |
| **GroupBy** | **1.55ms** | **<1ms** | **1-pass mean** | ‚è∏Ô∏è **NEXT**          |
| Join        | 16ms       | <500ms   | Column memcpy   | ‚úÖ **97.3% faster!** |

**Target**: 5/5 benchmarks passing (currently 3/5)

### When to Optimize

**‚úÖ DO optimize when**:

- Performance target missed (benchmark failing)
- Profiling identifies clear bottleneck
- Have time budget allocated (Phase 1: 3 days)

**‚ùå DON'T optimize when**:

- Tests failing (fix correctness first)
- No profiling data (would be guessing)
- Target already met (premature optimization)

### SIMD Integration Pattern

**Available** (from `src/core/simd.zig`):

- `compareFloat64Batch()` - 2√ó throughput for comparisons
- `compareInt64Batch()` - 2√ó throughput for comparisons
- `findNextSpecialChar()` - 16√ó throughput for CSV scanning

**Usage Pattern**:

```zig
// Check if SIMD available
if (simd.simd_available and data.len >= simd_width) {
    return processWithSIMD(data);
}
// Fallback to scalar
return processScalar(data);
```

**When SIMD Helps**:

- ‚úÖ Contiguous data access (arrays, columns)
- ‚úÖ Simple operations (compare, add, multiply)
- ‚úÖ Data size >16 bytes (overhead cost)

**When SIMD Doesn't Help**:

- ‚ùå Random memory access (hash lookups)
- ‚ùå Complex branching (state machines)
- ‚ùå Small data (<16 bytes)

### Optimization Checklist

Before implementing:

- [ ] Measure baseline
- [ ] Profile bottleneck
- [ ] Estimate improvement
- [ ] Implement
- [ ] Verify correctness (tests pass)
- [ ] Measure again
- [ ] Document results

---

## Critical WebAssembly Pitfalls

> **‚ö†Ô∏è CRITICAL**: These mistakes were made in the initial Wasm implementation (2025-10-27). Read this section BEFORE writing any Wasm-related code.

### Pitfall #1: Stack Allocations in WebAssembly üî•

**THE MISTAKE**:

```zig
// ‚ùå FATAL ERROR - Will crash in browser!
var memory_buffer: [100 * 1024 * 1024]u8 = undefined; // 100MB on stack
var fba = std.heap.FixedBufferAllocator.init(&memory_buffer);
```

**WHY IT FAILS**:

- WebAssembly stack limit: **1-2MB** (varies by browser)
- This allocates 100MB on the stack ‚Üí **instant stack overflow**
- Code compiles fine, but crashes on first function call in browser

**THE FIX**:

```zig
// ‚úÖ CORRECT - Use Wasm linear memory with @wasmMemoryGrow
var heap_start: usize = undefined;
var heap_size: usize = 0;
const INITIAL_HEAP_PAGES: u32 = 1600; // 1600 pages √ó 64KB = 100MB

fn initHeap() !void {
    const current_pages = @wasmMemorySize(0);
    const needed_pages = INITIAL_HEAP_PAGES;

    if (current_pages < needed_pages) {
        const grown = @wasmMemoryGrow(0, needed_pages - current_pages);
        std.debug.assert(grown != @maxValue(u32)); // Growth succeeded
    }

    heap_start = current_pages * 64 * 1024; // 64KB per page
    heap_size = needed_pages * 64 * 1024;

    std.debug.assert(heap_start > 0);
    std.debug.assert(heap_size >= 100 * 1024 * 1024);
}
```

**RULE**: Never allocate >1KB on stack in WebAssembly. Use `@wasmMemoryGrow()` for heap.

---

### Pitfall #2: Using `usize` in Wasm Exports üî•

**THE MISTAKE**:

```zig
// ‚ùå WRONG - usize is architecture-dependent
export fn rozes_getColumnF64(
    handle: i32,
    col_name_ptr: [*]const u8,
    col_name_len: u32,
    out_ptr: *usize,  // ‚ùå wasm32 vs wasm64 difference!
    out_len: *u32,
) i32 {
    out_ptr.* = @intFromPtr(data.ptr); // ‚ùå Changes size
}
```

**WHY IT FAILS**:

- Tiger Style requires **explicit types** (not `usize`)
- `usize` = 32-bit in wasm32, 64-bit in wasm64
- JavaScript expects consistent pointer size
- Memory layout breaks between architectures

**THE FIX**:

```zig
// ‚úÖ CORRECT - Explicit u32 for wasm32
export fn rozes_getColumnF64(
    handle: i32,
    col_name_ptr: [*]const u8,
    col_name_len: u32,
    out_ptr: *u32,  // ‚úÖ Explicit 32-bit
    out_len: *u32,
) i32 {
    const ptr_val: u32 = @intCast(@intFromPtr(data.ptr));
    out_ptr.* = ptr_val;

    std.debug.assert(ptr_val != 0); // Non-null
    std.debug.assert(out_len.* == @intCast(data.len)); // Verify
}
```

**RULE**: Always use `u32` (not `usize`) for Wasm32 pointers and sizes.

---

### Pitfall #3: Insufficient Assertions in Wasm Functions üî•

**THE MISTAKE**:

```zig
// ‚ùå WRONG - Only 1 assertion (Tiger Style requires 2+)
fn register(self: *DataFrameRegistry, df: *DataFrame) !i32 {
    std.debug.assert(self.next_id < MAX_DATAFRAMES * 2); // Only 1!

    var i: u32 = 0;
    while (i < MAX_DATAFRAMES) : (i += 1) {
        if (self.frames[i] == null) {
            self.frames[i] = df;
            self.next_id = i + 1;
            return @intCast(i);
        }
    }
    return error.TooManyDataFrames;
}
```

**WHY IT FAILS**:

- Tiger Style: **2+ assertions per function** (hard rule)
- Missing: null pointer check, post-loop assertion
- Wasm debugging is harder ‚Üí need more assertions

**THE FIX**:

```zig
// ‚úÖ CORRECT - 3 assertions
fn register(self: *DataFrameRegistry, df: *DataFrame) !i32 {
    std.debug.assert(self.next_id < MAX_DATAFRAMES * 2); // Pre-condition #1
    std.debug.assert(df != @as(*DataFrame, @ptrFromInt(0))); // Pre-condition #2: Non-null

    var i: u32 = 0;
    while (i < MAX_DATAFRAMES) : (i += 1) {
        if (self.frames[i] == null) {
            self.frames[i] = df;
            self.next_id = i + 1;
            return @intCast(i);
        }
    }

    std.debug.assert(i == MAX_DATAFRAMES); // Post-condition #3: Loop exhausted
    return error.TooManyDataFrames;
}
```

**RULE**: Every function needs **2+ assertions**. Post-loop assertions are mandatory.

---

### Pitfall #4: Missing Error Context in Data Processing üî•

**THE MISTAKE**:

```zig
// ‚ùå WRONG - Silent error, no context
df_ptr.* = parser.toDataFrame() catch |err| {
    allocator.destroy(df_ptr);
    return @intFromEnum(ErrorCode.fromError(err));
    // User sees: "Error -2" ‚Üê USELESS!
};
```

**WHY IT FAILS**:

- CSV parsing fails at row 47,823 of 100K rows
- User sees generic error code: `-2` (InvalidFormat)
- **No row number, no column, no problematic data**
- Hours wasted debugging

**THE FIX**:

```zig
// ‚úÖ CORRECT - Log error context with row/column
df_ptr.* = parser.toDataFrame() catch |err| {
    // Log BEFORE cleanup
    std.log.err("CSV parsing failed: {} at row {} col {} - field: '{s}'", .{
        err,
        parser.current_row_index,
        parser.current_col_index,
        parser.current_field.items[0..@min(50, parser.current_field.items.len)],
    });

    allocator.destroy(df_ptr);
    return @intFromEnum(ErrorCode.fromError(err));
};
```

**REQUIRED**: Add to CSVParser:

```zig
pub const CSVParser = struct {
    // ... existing fields
    current_row_index: u32,   // ‚úÖ ADD THIS
    current_col_index: u32,   // ‚úÖ ADD THIS
    // ...
};
```

**RULE**: Always log row/column numbers for data processing errors. Generic error codes are useless.

---

### Pitfall #5: JavaScript Memory Layout Assumptions üî•

**THE MISTAKE**:

```javascript
// ‚ùå WRONG - Overwrites memory at offset 0!
const csvPtr = 0; // Hardcoded offset 0
const csvArray = new Uint8Array(wasm.memory.buffer);
csvArray.set(csvBytes, csvPtr); // ‚ùå Destroys Wasm globals/stack!
```

**WHY IT FAILS**:

- Wasm memory offset 0 contains globals and stack
- Writing CSV data there **corrupts memory silently**
- Hard to debug (intermittent crashes)

**THE FIX**:

```zig
// 1. Export allocation functions in wasm.zig
export fn rozes_alloc(size: u32) u32 {
    std.debug.assert(size > 0);
    std.debug.assert(size <= 1_000_000_000); // 1GB max

    const allocator = getAllocator();
    const mem = allocator.alloc(u8, size) catch return 0;

    const ptr: u32 = @intCast(@intFromPtr(mem.ptr));
    std.debug.assert(ptr != 0); // Non-null
    return ptr;
}

export fn rozes_free_buffer(ptr: u32, size: u32) void {
    std.debug.assert(ptr != 0);
    std.debug.assert(size > 0);

    const allocator = getAllocator();
    const mem = @as([*]u8, @ptrFromInt(ptr))[0..size];
    allocator.free(mem);
}
```

```javascript
// 2. Use in JavaScript
const csvBytes = new TextEncoder().encode(csvText);
const csvPtr = wasm.instance.exports.rozes_alloc(csvBytes.length);

if (csvPtr === 0) {
  throw new RozesError(ErrorCode.OutOfMemory, "Failed to allocate CSV buffer");
}

try {
  const csvArray = new Uint8Array(wasm.memory.buffer, csvPtr, csvBytes.length);
  csvArray.set(csvBytes);

  const handle = wasm.instance.exports.rozes_parseCSV(
    csvPtr,
    csvBytes.length,
    0,
    0
  );
  checkResult(handle, "Failed to parse CSV");
  return new DataFrame(handle, wasm);
} finally {
  wasm.instance.exports.rozes_free_buffer(csvPtr, csvBytes.length);
}
```

**RULE**: Never write to hardcoded Wasm memory offsets. Always allocate via exported functions.

---

### Pitfall #6: Redundant Bounds Checks After Assertions üî¥

**THE MISTAKE**:

```zig
// ‚ùå WRONG - Redundant check after assertion
fn get(self: *DataFrameRegistry, handle: i32) ?*DataFrame {
    std.debug.assert(handle >= 0); // Assertion

    if (handle < 0 or handle >= MAX_DATAFRAMES) return null; // ‚ùå Redundant!
    const idx: u32 = @intCast(handle);
    return self.frames[idx];
}
```

**WHY IT FAILS**:

- Wastes CPU cycles checking twice
- Assertion already catches invalid handles in debug
- Release builds skip assertions, so check is needed BUT should be first

**THE FIX**:

```zig
// ‚úÖ CORRECT - Assertions only (debug) or check only (release)
fn get(self: *DataFrameRegistry, handle: i32) ?*DataFrame {
    std.debug.assert(handle >= 0); // Pre-condition
    std.debug.assert(handle < MAX_DATAFRAMES); // Bounds check

    const idx: u32 = @intCast(handle); // Panics if out of range
    const result = self.frames[idx];

    std.debug.assert(result == null or @intFromPtr(result.?) != 0); // Post-condition
    return result;
}
```

**RULE**: Don't duplicate assertions with runtime checks. Use assertions in debug, rely on them in release.

---

### Pitfall #7: Missing Post-Loop Assertions üî¥

**THE MISTAKE**:

```zig
// ‚ùå WRONG - Loop finishes but no assertion
var i: u32 = 0;
while (i < MAX_DATAFRAMES) : (i += 1) {
    if (self.frames[i] == null) {
        self.frames[i] = df;
        return @intCast(i);
    }
}
// ‚ùå Missing: std.debug.assert(i == MAX_DATAFRAMES);
return error.TooManyDataFrames;
```

**WHY IT FAILS**:

- Tiger Style requires post-loop assertions
- Verifies loop terminated correctly
- Catches off-by-one errors

**THE FIX**:

```zig
// ‚úÖ CORRECT - Post-loop assertion
var i: u32 = 0;
while (i < MAX_DATAFRAMES) : (i += 1) {
    if (self.frames[i] == null) {
        self.frames[i] = df;
        return @intCast(i);
    }
}
std.debug.assert(i == MAX_DATAFRAMES); // ‚úÖ Post-condition
return error.TooManyDataFrames;
```

**RULE**: Every bounded loop needs a post-loop assertion verifying termination condition.

---

### WebAssembly Checklist for Code Review

Before committing any Wasm code, verify:

- [ ] **No stack allocations >1KB** (use `@wasmMemoryGrow()`)
- [ ] **All pointer types are `u32`** (not `usize`)
- [ ] **Every function has 2+ assertions**
- [ ] **Post-loop assertions on all bounded loops**
- [ ] **Error logging includes row/column context**
- [ ] **JavaScript allocates via exported functions** (not hardcoded offsets)
- [ ] **No redundant bounds checks after assertions**
- [ ] **Memory alignment validated** (8-byte for Float64/Int64)
- [ ] **Check Wasm size after changes** (smaller is better)

**If ANY checkbox is unchecked ‚Üí DO NOT COMMIT.**

---

### Pitfall #8: WebAssembly Binary Size Bloat üü°

**THE OBSERVATION** (2025-10-27):

```bash
# Before Tiger Style fixes
zig-out/bin/rozes.wasm: 47KB (but crashed in browser)

# After Tiger Style fixes
zig-out/bin/rozes.wasm: 52KB (+5KB, but works correctly)
```

**WHY SIZE INCREASED**:
Adding safety features increases code size:

1. **Error logging code**: `std.log.err()` with string formatting (+2KB)
2. **New exports**: `rozes_alloc()` and `rozes_free_buffer()` (+1KB)
3. **Row/column tracking**: Additional fields and logic (+1KB)
4. **Assertions**: 30+ new assertions add debug info (+1KB)

**IMPORTANT TRADEOFF**:

- ‚úÖ **47KB binary** = crashes instantly (unusable)
- ‚úÖ **52KB binary** = works correctly with meaningful errors (usable)

**Better is WORKING, not smaller!**

**LESSON**: Binary size is a secondary concern compared to correctness:

```
Correctness > Safety > Size > Speed
```

**When to Optimize Size**:

- ‚úÖ After Tiger Style compliance is achieved
- ‚úÖ After all tests pass
- ‚úÖ Use `strip` and `wasm-opt` tools
- ‚úÖ Profile which functions are largest
- ‚ùå NOT by removing assertions
- ‚ùå NOT by removing error logging
- ‚ùå NOT by sacrificing safety

**Size Optimization Strategies** (for 0.2.0+):

1. Use `wasm-opt -Oz` from Binaryen (can save 20-30%)
2. Use `wasm-strip` to remove debug info (release builds only)
3. Lazy-load rarely-used functions
4. Use comptime to reduce runtime code
5. Pool string constants

**Acceptable Size Range**:

- **MVP (0.1.0)**: 50-100KB is fine
- **Production (0.2.0+)**: Target <80KB after optimization

**DO NOT** sacrifice correctness for a few KB!

---

### Pitfall #9: WASM Size Optimization Strategy üü¢

**CURRENT STATUS** (2025-10-27):

```bash
# After Phase 1 optimizations
zig-out/bin/rozes.wasm: 74 KB minified (~40 KB gzipped)

# Competitive benchmark
Papa Parse: 18.9 KB minified (6.8 KB gzipped)
csv-parse: 28.4 KB minified (7.0 KB gzipped)

# Target: <32 KB minified (<10 KB gzipped)
```

**OPTIMIZATION PHASES**:

#### Phase 1: Build System (COMPLETED - 14% reduction)

```bash
# Before: 86 KB
# After: 74 KB

# What we did:
1. Removed rozes_getColumnString stub (unimplemented)
2. Added comptime conditional logging
3. Integrated wasm-opt with --enable-bulk-memory
```

**Build Configuration** (`build.zig`):

```zig
// Development build: Debug mode, keep all logging
const wasm_dev = b.addExecutable(.{
    .optimize = .Debug,  // ~120 KB
});

// Production build: ReleaseSmall + wasm-opt
const wasm_prod = b.addExecutable(.{
    .optimize = .ReleaseSmall,  // Minimize size
});

// Run wasm-opt post-build
const wasm_opt = b.addSystemCommand(&[_][]const u8{
    "wasm-opt",
    "-Oz",                      // Maximum size optimization
    "--enable-bulk-memory",     // Required for Zig WASM
    "--strip-debug",
    "--strip-producers",
    "--strip-dwarf",
    "--converge",               // Repeat until no gains
});
```

**Commands**:

```bash
# Production (optimized, 74 KB)
zig build wasm

# Development (debug, ~120 KB)
zig build wasm-dev
```

**Comptime Conditional Logging** (`src/wasm.zig`):

```zig
const builtin = @import("builtin");
const enable_logging = builtin.mode == .Debug;

fn logError(comptime fmt: []const u8, args: anytype) void {
    if (enable_logging) {
        std.log.err(fmt, args);  // Only in debug builds
    }
}

// Usage: Production builds strip out all logging strings
logError("CSV parsing failed: {} at row {}", .{err, row_idx});
```

**Savings**: 2-3 KB (logging strings removed in release)

---

#### Phase 2: Dead Code Elimination (NEXT - Target: 45 KB)

**Remove Unused Exports**:

```zig
// ‚ùå BEFORE - Unimplemented function (adds ~1 KB)
export fn rozes_getColumnString(...) i32 {
    std.debug.assert(false);  // Not implemented
    return @intFromEnum(ErrorCode.TypeMismatch);
}

// ‚úÖ AFTER - Replaced with comment
// NOTE: String column export deferred to 0.2.0
// Browser tests use Int64/Float64/Bool columns only for MVP
```

**String Interning**:

```zig
// ‚ùå BEFORE - Duplicated error strings throughout code
return @intFromEnum(ErrorCode.OutOfMemory);
// ... 10 places with "Out of memory" string

// ‚úÖ AFTER - Single string table
const ErrorMessages = struct {
    pub const out_of_memory = "Out of memory";
    pub const invalid_format = "Invalid format";
};
```

**Expected**: 74 KB ‚Üí 45 KB (40% reduction)

---

#### Phase 3: Selective Assertions (Target: 32 KB)

**Debug-Only Assertion Wrapper**:

```zig
fn debugAssert(condition: bool) void {
    if (@import("builtin").mode == .Debug) {
        std.debug.assert(condition);
    }
}
```

**Keep Safety-Critical Assertions**:

```zig
// ‚úÖ KEEP in production (safety)
std.debug.assert(idx < self.length);        // Bounds check
std.debug.assert(handle >= 0);              // Null check
std.debug.assert(self.delimiter != 0);      // Invariant

// ‚úÖ MAKE DEBUG-ONLY (verification)
debugAssert(ptr_val != 0);                  // Redundant (checked above)
debugAssert(i == MAX_DATAFRAMES);           // Obvious from loop
debugAssert(@intFromPtr(result.?) != 0);    // Redundant pointer check
```

**Strategy**: Keep 60-70% of assertions (150-170 out of 248)

**Lazy DataFrame Registry**:

```zig
// ‚ùå BEFORE - Always allocates 8 KB
frames: [MAX_DATAFRAMES]?*DataFrame,  // 1000 √ó 8 bytes

// ‚úÖ AFTER - Grows as needed
frames: std.ArrayList(?*DataFrame),
// Start with capacity 4, grow on demand
```

**Expected**: 45 KB ‚Üí 32 KB (30% reduction)

---

#### Phase 4: Advanced Optimizations (IF NEEDED - Target: <28 KB)

**FixedBufferAllocator** (replaces GeneralPurposeAllocator):

```zig
// ‚ùå BEFORE - GPA has thread-safety overhead (~5-8 KB)
var gpa = std.heap.GeneralPurposeAllocator(.{}){};

// ‚úÖ AFTER - Fixed buffer for WASM
var fba: std.heap.FixedBufferAllocator = undefined;

fn initAllocator() !void {
    const pages_needed = (100 * 1024 * 1024) / (64 * 1024);
    const grown = @wasmMemoryGrow(0, pages_needed);
    std.debug.assert(grown != @maxValue(u32));

    const heap_mem = @as([*]u8, @ptrFromInt(heap_start))[0..HEAP_SIZE];
    fba = std.heap.FixedBufferAllocator.init(heap_mem);
}
```

**Manual Export List** (disable rdynamic):

```zig
// ‚ùå BEFORE - Exports ALL functions marked 'export'
wasm.rdynamic = true;

// ‚úÖ AFTER - Only export what's needed
wasm.rdynamic = false;
wasm.export_symbol_names = &[_][]const u8{
    "rozes_parseCSV",
    "rozes_getDimensions",
    "rozes_getColumnF64",
    "rozes_getColumnI64",
    "rozes_free",
    "rozes_alloc",
    "rozes_free_buffer",
};
```

**LTO (Link-Time Optimization)**:

```zig
wasm.want_lto = true;  // Cross-function optimization, 5-10% reduction
```

**Expected**: 32 KB ‚Üí 28 KB (15% reduction)

---

#### Size Optimization Checklist

Before optimizing:

- [ ] **Tiger Style compliance achieved** (all tests pass)
- [ ] **Correctness verified** (browser tests work)
- [ ] **Performance targets met** (100K rows <1s)

Optimization order:

- [ ] Phase 1: Build system + comptime logging ‚úÖ DONE (86 KB ‚Üí 74 KB)
- [ ] Phase 2: Dead code removal (Target: 45 KB)
- [ ] Phase 3: Selective assertions + lazy registry (Target: 32 KB)
- [ ] Phase 4: Advanced optimizations (IF >32 KB still)

**Success Metrics**:
| Phase | Size | vs Papa Parse | vs csv-parse | Status |
|-------|------|---------------|--------------|--------|
| Current | 74 KB | 3.9x | 2.6x | üü° Need optimization |
| Phase 2 | 45 KB | 2.4x | 1.6x | üü° Acceptable MVP |
| Phase 3 | 32 KB | 1.7x | 1.1x | üü¢ **Competitive** |
| Phase 4 | 28 KB | 1.5x | 1.0x | üü¢ Good |

**Gzipped (what users download)**:

- 74 KB ‚Üí ~40 KB gzipped (5.9x vs Papa Parse 6.8 KB)
- 32 KB ‚Üí ~10 KB gzipped (1.5x vs Papa Parse) ‚úÖ **Target**

**RULE**: Don't optimize until Phase 1 complete. Don't sacrifice safety for size.

---

## Tiger Style Learnings from 0.2.0 & 0.3.0 Implementation

> **üéØ UPDATED (2025-10-28)**: Critical learnings from implementing string support & sort operations.

### Learning #1: Buffer Growth Loops MUST Be Bounded üî•

**Violation**: Unbounded `while (new_size < needed_size) { new_size *= 2; }` allows infinite loops on overflow or malicious input.

**Solution**: Use explicit MAX constant, counter, post-assertion:

```zig
const MAX_BUFFER_GROWTH_ITERATIONS: u32 = 32;
var growth_iterations: u32 = 0;
while (new_size < needed_size and growth_iterations < MAX_BUFFER_GROWTH_ITERATIONS) : (growth_iterations += 1) {
    new_size = @min(new_size * 2, MAX_BUFFER_SIZE);
}
std.debug.assert(growth_iterations < MAX_BUFFER_GROWTH_ITERATIONS or new_size >= needed_size);
```

---

### Learning #2: Simple Functions Need Creative Assertions üî•

**Violation**: Single assertion in getter (Tiger Style requires 2+).

**Solutions** (pick appropriate pattern):

- **Pattern A**: Input + output assertions
- **Pattern B**: Invariant + type check
- **Pattern C**: Runtime + comptime assertion

```zig
// ‚úÖ Example: Assert invariant + non-null pointer
std.debug.assert(self.length <= MAX_ROWS);
std.debug.assert(@intFromPtr(self) != 0);
```

---

### Learning #3: Function Length - The 70-Line Hard Limit üî•

**Violation**: Functions >70 lines must be split by responsibility.

**Approach**: Extract type-specific helpers

```zig
// Main orchestration ‚â§70 lines
fn fillDataFrame(...) !void {
    for (df.columns, 0..) |*col, idx| {
        switch (column_types[idx]) {
            .Int64 => try fillInt64Column(col, rows, idx),
            .Float64 => try fillFloat64Column(col, rows, idx),
            // ...
        }
    }
}

// Type-specific helpers ‚â§40 lines each
fn fillInt64Column(col: *Series, rows: []const [][]const u8, col_idx: usize) !void {
    // ...
}
```

**Benefits**: Single responsibility, testable, reusable.

---

### Learning #4: Error Context is Data Integrity üî•

**Violation**: Silent errors with generic codes (user sees "Error -2", no context).

**Solution**: Log row, column name, field value:

```zig
buffer[row_idx] = std.fmt.parseFloat(f64, row[col_idx]) catch |err| {
    std.log.err("Parse failed at row {}, col {} ('{s}'): field='{s}' - {}",
        .{row_idx, col_idx, df.columns[col_idx].name, row[col_idx], err});
    return error.TypeMismatch;
};
```

**Example output**: `Parse failed at row 47823, col 3 ('price'): field='$19.99' - InvalidCharacter`

User fixes issue immediately instead of hours debugging.

---

### Learning #5: String Operations Need Performance Notes üî•

**Violation**: Undocumented performance characteristics.

**Solution**: Document complexity, growth strategy, optimization hints:

````zig
/// Appends string value to series
///
/// **Performance**: O(n log n) worst case, O(n) amortized (exponential 2√ó growth)
/// **Optimization**: Pre-allocate with estimated capacity:
/// ```zig
/// const col = try StringColumn.init(allocator,
///     estimated_capacity, estimated_buffer_size);
/// ```
pub fn appendString(...) !void
````

---

### Learning #6: WASM Size Optimization - Low-Hanging Fruit üî•

**Discovery**: 102 KB ‚Üí 74 KB (27% reduction) with simple optimizations.

**Techniques**:

1. **String interning**: Deduplicate error messages (~2 KB)
2. **Conditional logging**: Strip in release builds (~3 KB)
3. **Inline hot paths**: Small frequently-called functions (~1 KB)
4. **Lazy allocation**: ArrayList instead of fixed arrays (~8 KB)
5. **Conditional assertions**: Debug-only where safe (~500 bytes)

**Rule**: Apply low-hanging fruit first. Don't sacrifice safety for size.

---

### Learning #7: Type Inference - Default to String, Not Error üî•

**Discovery**: Conformance jumped from 17% ‚Üí 97% by defaulting to String instead of erroring.

**Pattern**:

```zig
fn inferColumnType(...) ValueType {
    // Try Bool, Int64, Float64 first
    if (all_bool) return .Bool;
    if (all_int) return .Int64;
    if (all_float) return .Float64;

    return .String; // ‚úÖ Universal fallback, no error
}
```

**Key insight**: String is universal fallback - preserves all data, never rejects valid CSV.

---

### Learning #8: Test Coverage - 85% is Good, But Know the Gaps üî•

**Achievement**: 83 tests, 85% coverage, 97% conformance.

**Known gaps** (15% uncovered):

1. **Error recovery paths** (~5%): Buffer/registry limits, UTF-8 validation failures
2. **Edge case combinations** (~5%): MAX_COLUMNS, u32 max rows, extreme data
3. **WASM-specific paths** (~3%): Memory growth failures, encoding edge cases
4. **Comptime assertions** (~2%): Struct size/alignment checks

**Rule**: 85% excellent for MVP. Document gaps, add stress tests later.

---

### Learning #9: IEEE 754 NaN Handling - The Silent Killer üî•

**Discovery**: `std.math.order(a, b)` panics on NaN, crashing sort operations.

**Problem**: NaN common in real data (sensor failures, 0/0, data import errors). One NaN crashes 1M-row sort.

**Solution**: Check NaN before comparison:

```zig
.Float64 => blk: {
    const a = data[idx_a];
    const b = data[idx_b];

    const a_is_nan = std.math.isNan(a);
    const b_is_nan = std.math.isNan(b);

    if (a_is_nan and b_is_nan) {
        break :blk std.math.order(idx_a, idx_b); // Preserve order
    } else if (a_is_nan) {
        break :blk .gt; // NaN sorts to end
    } else if (b_is_nan) {
        break :blk .lt;
    } else {
        break :blk std.math.order(a, b); // Normal comparison
    }
}
```

**When to check**: Comparisons (sort, min, max), aggregations, type inference, export.

**Impact**: 112/113 tests ‚Üí 113/113 tests. Production-ready.

### Learning #10: For-Loops Over Runtime Data are Tiger Style Violations üî•

**Discovery**: 6 unbounded for-loops found in new modules - all over user-controlled data.

**Violation**: `for (items) |item|` over runtime collections (categories, strings, columns, rows).

**Risk**: Malicious input triggers unbounded iteration (1M categories, GB strings, 100K columns).

**Solution**: Bounded while loops with MAX constant:

```zig
// ‚úÖ CORRECT
std.debug.assert(items.len <= MAX_ITEMS);

var i: u32 = 0;
while (i < MAX_ITEMS and i < items.len) : (i += 1) {
    // process items[i]
}
std.debug.assert(i == items.len);
```

**When for-loops OK**:

- ‚úÖ Comptime iteration: `comptime for (type_list) |T|`
- ‚úÖ Fixed arrays: `for ([_]ValueType{.Int64, .Float64}) |t|`
- ‚ùå Runtime data: `for (df.columns)`, `for (rows)`, `for (str, 0..)`

**Detection**: `grep -n "for.*|" src/**/*.zig | grep -v "comptime"`

**Impact**: 6 violations fixed ‚Üí 0 unbounded loops.

---

### Learning #11: For-Loops in Aggregations Need Explicit Bounds üî•

**Discovery**: 9 unbounded for-loops in groupBy/join operations.

**Risk**: Large groups (1M rows with same key) or join collisions (100K matches) trigger unbounded iteration.

**Pattern**: Same as Learning #10 - replace with bounded while loops.

**Special case - join collision handling**:

```zig
var entry_idx: u32 = 0;
while (entry_idx < MAX_MATCHES_PER_KEY and entry_idx < entries.len) : (entry_idx += 1) {
    // process match
}

if (entry_idx >= MAX_MATCHES_PER_KEY and entry_idx < entries.len) {
    std.log.warn("Join truncated: {} matches (limit {})",
        .{entries.len, MAX_MATCHES_PER_KEY});
}
```

**Impact**: 9 violations fixed in groupby.zig (3) and join.zig (6).

---

## Source Organization

### Directory Structure

```
src/
‚îú‚îÄ‚îÄ core/                      # Core DataFrame engine
‚îÇ   ‚îú‚îÄ‚îÄ types.zig              # Core type definitions
‚îÇ   ‚îú‚îÄ‚îÄ allocator.zig          # Memory management utilities
‚îÇ   ‚îú‚îÄ‚îÄ series.zig             # Series implementation
‚îÇ   ‚îú‚îÄ‚îÄ dataframe.zig          # DataFrame implementation
‚îÇ   ‚îî‚îÄ‚îÄ operations.zig         # DataFrame operations (filter, select, etc.)
‚îú‚îÄ‚îÄ csv/                       # CSV parsing and export
‚îÇ   ‚îú‚îÄ‚îÄ parser.zig             # CSV parser (RFC 4180)
‚îÇ   ‚îú‚îÄ‚îÄ export.zig             # CSV serialization
‚îÇ   ‚îú‚îÄ‚îÄ types.zig              # CSVOptions, ParseState
‚îÇ   ‚îú‚îÄ‚îÄ inference.zig          # Type inference
‚îÇ   ‚îî‚îÄ‚îÄ bom.zig                # BOM detection/handling
‚îú‚îÄ‚îÄ bindings/                  # Platform bindings
‚îÇ   ‚îú‚îÄ‚îÄ wasm/                  # WebAssembly
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ bridge.zig         # JS ‚Üî Wasm memory bridge
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ exports.zig        # Exported Wasm functions
‚îÇ   ‚îî‚îÄ‚îÄ node/                  # Node.js N-API (optional)
‚îÇ       ‚îî‚îÄ‚îÄ addon.zig
‚îî‚îÄ‚îÄ rozes.zig                  # Main API surface (public exports)
```

### Module Responsibilities

#### `core/types.zig` - Type Definitions

**Purpose**: Define all core types used throughout the project
**Exports**:

- `ValueType` enum
- `ColumnDesc` struct
- `CSVOptions` struct
- `ParseMode` enum
- `ParseError` struct

**Pattern**:

```zig
//! Core type definitions for Rozes DataFrame library.
//!
//! This module contains all fundamental types used across the codebase.
//! See docs/RFC.md Section 4.1 for type specifications.

const std = @import("std");

/// Supported data types for DataFrame columns
pub const ValueType = enum {
    Int64,
    Float64,
    String,
    Bool,
    Null,

    /// Returns the size in bytes for this type
    pub fn sizeOf(self: ValueType) usize {
        return switch (self) {
            .Int64 => @sizeOf(i64),
            .Float64 => @sizeOf(f64),
            .Bool => @sizeOf(bool),
            .String, .Null => 0, // Variable size
        };
    }
};

/// Column descriptor with name and type
pub const ColumnDesc = struct {
    name: []const u8,
    valueType: ValueType,
};

// ... more types
```

#### `core/series.zig` - Series Implementation

**Purpose**: 1D homogeneous typed array
**Exports**:

- `Series` struct
- Column accessor methods

**Pattern**:

```zig
//! Series - 1D homogeneous typed array
//!
//! A Series represents a single column of data with a uniform type.
//! Data is stored contiguously for cache efficiency.

const std = @import("std");
const types = @import("types.zig");
const ValueType = types.ValueType;

pub const Series = struct {
    name: []const u8,
    valueType: ValueType,
    data: union(ValueType) {
        Int64: []i64,
        Float64: []f64,
        String: StringColumn,
        Bool: []bool,
        Null: void,
    },
    length: u32,

    /// Get the length of the Series
    pub fn len(self: *const Series) u32 {
        std.debug.assert(self.length > 0); // Series should have data
        return self.length;
    }

    /// Get value at index (with type checking)
    pub fn get(self: *const Series, idx: u32) ?Value {
        std.debug.assert(idx < self.length); // Bounds check

        return switch (self.valueType) {
            .Int64 => Value{ .Int64 = self.data.Int64[idx] },
            .Float64 => Value{ .Float64 = self.data.Float64[idx] },
            .Bool => Value{ .Bool = self.data.Bool[idx] },
            .String => Value{ .String = self.data.String.get(idx) },
            .Null => null,
        };
    }

    /// Access as Float64 array (returns null if wrong type)
    pub fn asFloat64(self: *const Series) ?[]f64 {
        std.debug.assert(self.length > 0);

        return switch (self.valueType) {
            .Float64 => self.data.Float64,
            else => null,
        };
    }

    // ... more methods
};

/// String column with offset table for efficient storage
const StringColumn = struct {
    offsets: []u32,      // offsets[i] = start of string i
    buffer: []u8,        // contiguous UTF-8 data
    row_count: u32,

    pub fn get(self: *const StringColumn, idx: u32) []const u8 {
        std.debug.assert(idx < self.row_count);

        const start = if (idx == 0) 0 else self.offsets[idx - 1];
        const end = self.offsets[idx];

        std.debug.assert(start <= end);
        std.debug.assert(end <= self.buffer.len);

        return self.buffer[start..end];
    }
};
```

#### `core/dataframe.zig` - DataFrame Implementation

**Purpose**: 2D tabular data structure
**Exports**:

- `DataFrame` struct
- CSV import/export functions
- Column operations

**Pattern**:

```zig
//! DataFrame - 2D tabular data structure
//!
//! DataFrame stores data in columnar format for efficient operations.
//! Each column is a Series with homogeneous type.

const std = @import("std");
const types = @import("types.zig");
const Series = @import("series.zig").Series;

pub const DataFrame = struct {
    allocator: std.mem.Allocator,
    arena: *std.heap.ArenaAllocator,  // For lifecycle management
    columns: []ColumnDesc,
    series: []Series,
    rowCount: u32,

    /// Create DataFrame with specified columns
    pub fn create(
        allocator: std.mem.Allocator,
        columns: []ColumnDesc,
        rowCount: u32,
    ) !DataFrame {
        std.debug.assert(columns.len > 0); // Need at least 1 column
        std.debug.assert(rowCount > 0); // Need at least 1 row

        // Create arena for all allocations
        const arena = try allocator.create(std.heap.ArenaAllocator);
        arena.* = std.heap.ArenaAllocator.init(allocator);
        errdefer {
            arena.deinit();
            allocator.destroy(arena);
        }

        const arena_alloc = arena.allocator();

        // Allocate columns and series
        const df_columns = try arena_alloc.dupe(ColumnDesc, columns);
        const df_series = try arena_alloc.alloc(Series, columns.len);

        return DataFrame{
            .allocator = allocator,
            .arena = arena,
            .columns = df_columns,
            .series = df_series,
            .rowCount = rowCount,
        };
    }

    /// Free all DataFrame memory (single operation via arena)
    pub fn free(self: DataFrame) void {
        self.arena.deinit();
        self.allocator.destroy(self.arena);
    }

    /// Get column by name
    pub fn column(self: *const DataFrame, name: []const u8) ?*const Series {
        std.debug.assert(self.series.len > 0);

        for (self.series, 0..) |*series, i| {
            if (std.mem.eql(u8, self.columns[i].name, name)) {
                return series;
            }
        }
        return null;
    }

    // ... more methods
};
```

#### `csv/parser.zig` - CSV Parser

**Purpose**: RFC 4180 compliant CSV parsing
**Exports**:

- `CSVParser` struct
- Parsing functions

**Pattern**:

```zig
//! CSV Parser - RFC 4180 Compliant
//!
//! One-pass parser with state machine for efficient parsing.
//! Converts CSV text to columnar DataFrame.

const std = @import("std");
const types = @import("../core/types.zig");
const DataFrame = @import("../core/dataframe.zig").DataFrame;

const ParserState = enum {
    Start,
    InField,
    InQuotedField,
    QuoteInQuoted,
    EndOfRecord,
};

const MAX_CSV_SIZE: u32 = 1_000_000_000; // 1GB max
const MAX_COLUMNS: u32 = 10_000;
const MAX_ROWS: u32 = 4_000_000_000; // u32 limit

pub const CSVParser = struct {
    allocator: std.mem.Allocator,
    buffer: []const u8,
    pos: u32,
    state: ParserState,
    opts: types.CSVOptions,
    current_field: std.ArrayList(u8),
    current_row: std.ArrayList([]const u8),
    rows: std.ArrayList([][]const u8),

    pub fn init(
        allocator: std.mem.Allocator,
        buffer: []const u8,
        opts: types.CSVOptions,
    ) !CSVParser {
        std.debug.assert(buffer.len > 0); // Non-empty buffer
        std.debug.assert(buffer.len <= MAX_CSV_SIZE); // Size check

        return CSVParser{
            .allocator = allocator,
            .buffer = buffer,
            .pos = 0,
            .state = .Start,
            .opts = opts,
            .current_field = std.ArrayList(u8).init(allocator),
            .current_row = std.ArrayList([]const u8).init(allocator),
            .rows = std.ArrayList([][]const u8).init(allocator),
        };
    }

    /// Parse next field from CSV
    pub fn nextField(self: *CSVParser) !?[]const u8 {
        std.debug.assert(self.pos <= self.buffer.len);

        while (self.pos < self.buffer.len) {
            const char = self.buffer[self.pos];
            self.pos += 1;

            switch (self.state) {
                .Start => {
                    if (char == self.opts.quoteChar) {
                        self.state = .InQuotedField;
                    } else if (char == self.opts.delimiter) {
                        // Empty field
                        return try self.finishField();
                    } else if (char == '\n' or char == '\r') {
                        self.state = .EndOfRecord;
                        return null; // End of row
                    } else {
                        try self.current_field.append(char);
                        self.state = .InField;
                    }
                },
                .InField => {
                    if (char == self.opts.delimiter) {
                        self.state = .Start;
                        return try self.finishField();
                    } else if (char == '\n' or char == '\r') {
                        self.state = .EndOfRecord;
                        const field = try self.finishField();
                        return field;
                    } else {
                        try self.current_field.append(char);
                    }
                },
                .InQuotedField => {
                    if (char == self.opts.quoteChar) {
                        self.state = .QuoteInQuoted;
                    } else {
                        try self.current_field.append(char);
                    }
                },
                .QuoteInQuoted => {
                    if (char == self.opts.quoteChar) {
                        // Escaped quote
                        try self.current_field.append(self.opts.quoteChar);
                        self.state = .InQuotedField;
                    } else if (char == self.opts.delimiter) {
                        self.state = .Start;
                        return try self.finishField();
                    } else if (char == '\n' or char == '\r') {
                        self.state = .EndOfRecord;
                        return try self.finishField();
                    } else {
                        return error.InvalidQuoting;
                    }
                },
                .EndOfRecord => unreachable,
            }
        }

        // End of buffer
        if (self.current_field.items.len > 0) {
            return try self.finishField();
        }
        return null;
    }

    fn finishField(self: *CSVParser) ![]const u8 {
        const field = try self.current_field.toOwnedSlice();
        return field;
    }

    /// Parse entire CSV to DataFrame
    pub fn toDataFrame(self: *CSVParser) !DataFrame {
        // Implementation in Phase 3
    }
};
```

---

## Zig Implementation Patterns

### Pattern 1: Bounded Loops with Explicit Limits

**Always set maximum iterations**:

```zig
const MAX_ROWS: u32 = 4_000_000_000; // u32 limit

pub fn parseCSV(buffer: []const u8) !DataFrame {
    std.debug.assert(buffer.len > 0); // Pre-condition

    var row_count: u32 = 0;
    while (row_count < MAX_ROWS) : (row_count += 1) {
        // Parse row
        if (is_end_of_file) break;
    }

    std.debug.assert(row_count <= MAX_ROWS); // Post-condition
    return dataframe;
}
```

**Common Unbounded Loop Issues**:

1. **For loops over slices** - Need explicit MAX check:

```zig
// ‚ùå WRONG - No explicit bound
pub fn columnIndex(self: *const DataFrame, name: []const u8) ?usize {
    for (self.columnDescs, 0..) |desc, i| {  // What if columnDescs is corrupted?
        if (std.mem.eql(u8, desc.name, name)) return i;
    }
    return null;
}

// ‚úÖ CORRECT - Explicit bound with while loop
pub fn columnIndex(self: *const DataFrame, name: []const u8) ?u32 {
    std.debug.assert(name.len > 0);
    std.debug.assert(self.columnDescs.len <= MAX_COLS);

    var i: u32 = 0;
    while (i < MAX_COLS and i < self.columnDescs.len) : (i += 1) {
        if (std.mem.eql(u8, self.columnDescs[i].name, name)) {
            return i;
        }
    }

    std.debug.assert(i <= MAX_COLS); // Post-condition
    return null;
}
```

2. **Nested loops** - Both need bounds:

```zig
// ‚ùå WRONG - Nested unbounded loops
fn fillDataFrame(df: *DataFrame, rows: []const [][]const u8) !void {
    for (df.columns, 0..) |*col, col_idx| {
        for (rows, 0..) |row, row_idx| {
            // ... process
        }
    }
}

// ‚úÖ CORRECT - Both loops bounded
fn fillDataFrame(df: *DataFrame, rows: []const [][]const u8) !void {
    std.debug.assert(rows.len > 0);
    std.debug.assert(df.columns.len <= MAX_COLS);

    var col_idx: u32 = 0;
    while (col_idx < MAX_COLS and col_idx < df.columns.len) : (col_idx += 1) {
        var row_idx: u32 = 0;
        while (row_idx < MAX_ROWS and row_idx < rows.len) : (row_idx += 1) {
            // ... process
        }
        std.debug.assert(row_idx <= MAX_ROWS);
    }
    std.debug.assert(col_idx <= MAX_COLS);
}
```

3. **Character-by-character parsing** - Need field length limit:

```zig
// ‚ùå WRONG - No field length limit
pub fn nextField(self: *CSVParser) !?[]const u8 {
    while (self.pos < self.buffer.len) {  // What if one field is 1GB?
        const char = self.buffer[self.pos];
        self.pos += 1;
        try self.current_field.append(char);
    }
}

// ‚úÖ CORRECT - Field length bounded
const MAX_FIELD_LENGTH: u32 = 1_000_000; // 1MB per field

pub fn nextField(self: *CSVParser) !?[]const u8 {
    std.debug.assert(self.pos <= self.buffer.len);

    while (self.pos < self.buffer.len) {
        if (self.current_field.items.len >= MAX_FIELD_LENGTH) {
            return error.FieldTooLarge;
        }

        const char = self.buffer[self.pos];
        self.pos += 1;
        // ... process char
    }

    std.debug.assert(self.pos <= self.buffer.len);
}
```

### Pattern 2: Arena Allocator for Lifecycle Management

**Use arena for grouped allocations**:

```zig
pub fn fromCSVBuffer(
    allocator: std.mem.Allocator,
    buffer: []const u8,
    opts: CSVOptions,
) !DataFrame {
    // Create arena for all DataFrame allocations
    const arena = try allocator.create(std.heap.ArenaAllocator);
    arena.* = std.heap.ArenaAllocator.init(allocator);
    errdefer {
        arena.deinit();
        allocator.destroy(arena);
    }

    const arena_alloc = arena.allocator();

    // All allocations use arena_alloc
    const columns = try arena_alloc.alloc(ColumnDesc, col_count);
    const series = try arena_alloc.alloc(Series, col_count);

    // Single free via arena
    return DataFrame{ .arena = arena, /* ... */ };
}
```

### Pattern 3: Explicit Type Sizes

**Use u32 instead of usize**:

```zig
// ‚úÖ Correct - consistent across platforms
const row_index: u32 = 0;
const col_count: u32 = @intCast(df.columns.len);

// ‚ùå Wrong - platform-dependent
const row_index: usize = 0;
```

### Pattern 4: Tagged Unions for Variant Types

**Use tagged unions for type-safe variants**:

```zig
pub const Value = union(ValueType) {
    Int64: i64,
    Float64: f64,
    String: []const u8,
    Bool: bool,
    Null: void,

    pub fn asFloat64(self: Value) ?f64 {
        return switch (self) {
            .Float64 => |val| val,
            .Int64 => |val| @floatFromInt(val),
            else => null,
        };
    }
};
```

### Pattern 5: Comptime for Zero-Overhead Abstractions

**Use comptime for type-generic code**:

```zig
fn generateColumnAccessor(comptime T: type) type {
    return struct {
        pub fn get(data: []const T, idx: u32) T {
            std.debug.assert(idx < data.len);
            return data[idx];
        }

        pub fn sum(data: []const T) T {
            var total: T = 0;
            for (data) |val| total += val;
            return total;
        }
    };
}

const Float64Accessor = generateColumnAccessor(f64);
const Int64Accessor = generateColumnAccessor(i64);
```

---

## Tiger Style Enforcement

### 2+ Assertions Per Function

**Every function MUST have at least 2 assertions**:

```zig
pub fn get(self: *const Series, idx: u32) ?Value {
    std.debug.assert(idx < self.length);     // Assertion 1: Bounds check
    std.debug.assert(self.data != null);      // Assertion 2: Valid data

    return self.data[idx];
}
```

**Common Assertion Patterns**:

1. **Simple Getters/Setters** - Still need 2 assertions:

```zig
// ‚ùå WRONG - Only returns value
pub fn isEmpty(self: *const Series) bool {
    return self.length == 0;
}

// ‚úÖ CORRECT - Has pre/post assertions
pub fn isEmpty(self: *const Series) bool {
    std.debug.assert(self.length <= MAX_ROWS); // Invariant check
    const result = self.length == 0;
    std.debug.assert(result == (self.length == 0)); // Post-condition
    return result;
}
```

2. **Enum Methods** - Validate enum value:

```zig
// ‚ùå WRONG - No assertions
pub fn sizeOf(self: ValueType) ?u8 {
    return switch (self) {
        .Int64 => 8,
        .Float64 => 8,
        .Bool => 1,
        .String, .Null => null,
    };
}

// ‚úÖ CORRECT - Validate enum and result
pub fn sizeOf(self: ValueType) ?u8 {
    std.debug.assert(@intFromEnum(self) >= 0); // Valid enum value

    const result = switch (self) {
        .Int64 => 8,
        .Float64 => 8,
        .Bool => 1,
        .String, .Null => null,
    };

    std.debug.assert(result == null or result.? > 0); // Non-zero for fixed types
    return result;
}
```

3. **Validation Functions** - Check BEFORE errors:

```zig
// ‚ùå WRONG - Assertions after error checks
pub fn validate(self: CSVOptions) !void {
    std.debug.assert(self.delimiter != 0);

    if (self.previewRows == 0) return error.InvalidPreviewRows;

    std.debug.assert(self.previewRows > 0); // Redundant!
}

// ‚úÖ CORRECT - Assertions before errors
pub fn validate(self: CSVOptions) !void {
    std.debug.assert(self.delimiter != 0); // Pre-condition
    std.debug.assert(self.previewRows > 0 or
                    self.previewRows <= 10_000); // Range check

    if (self.previewRows == 0) return error.InvalidPreviewRows;
    if (self.previewRows > 10_000) return error.PreviewRowsTooLarge;
}
```

### Explicit Error Handling

**Never ignore errors**:

```zig
// ‚úÖ Correct - propagate error
const df = try DataFrame.fromCSVBuffer(allocator, buffer, opts);

// ‚úÖ Correct - handle explicitly
const df = DataFrame.fromCSVBuffer(allocator, buffer, opts) catch |err| {
    log.err("CSV parsing failed: {}", .{err});
    return error.InvalidCSV;
};

// ‚ö†Ô∏è Only with proof that error is impossible
const df = DataFrame.create(allocator, cols, 0) catch unreachable;

// ‚ùå Never ignore silently
const df = DataFrame.create(allocator, cols, 0) catch null;
```

**CRITICAL: Silent Error Handling = Data Loss**:

1. **Never catch and return default values**:

```zig
// ‚ùå CRITICAL DATA LOSS - User has no idea allocation failed!
pub fn columnNames(self: *const DataFrame) []const []const u8 {
    const allocator = self.arena.allocator();
    var names = allocator.alloc([]const u8, self.columns.len) catch return &[_][]const u8{};
    // ... returns empty array on allocation failure
}

// ‚úÖ CORRECT - Propagate error to caller
pub fn columnNames(self: *const DataFrame, allocator: std.mem.Allocator) ![]const []const u8 {
    std.debug.assert(self.columns.len > 0);
    std.debug.assert(self.columns.len <= MAX_COLS);

    var names = try allocator.alloc([]const u8, self.columns.len);
    // ... caller handles error
    return names;
}
```

2. **Never catch parse errors and default to 0**:

```zig
// ‚ùå CRITICAL DATA LOSS - "abc" becomes 0, user never knows!
for (rows, 0..) |row, row_idx| {
    buffer[row_idx] = std.fmt.parseInt(i64, row[col_idx], 10) catch 0;
    // ‚òùÔ∏è Silent data corruption
}

// ‚úÖ CORRECT - Fail fast in Strict mode
for (rows, 0..) |row, row_idx| {
    buffer[row_idx] = std.fmt.parseInt(i64, row[col_idx], 10) catch |err| {
        std.log.err("Failed to parse Int64 at row {}, col {}: '{}' - {}",
            .{row_idx, col_idx, row[col_idx], err});
        return error.TypeMismatch;
    };
}

// ‚úÖ ACCEPTABLE - Lenient mode with error tracking (0.2.0)
for (rows, 0..) |row, row_idx| {
    buffer[row_idx] = std.fmt.parseInt(i64, row[col_idx], 10) catch blk: {
        try self.errors.append(ParseError.init(
            row_idx, col_idx, "Invalid integer format", .TypeMismatch
        ));
        break :blk 0; // Explicit fallback with error logged
    };
}
```

### Functions ‚â§70 Lines

**Break large functions into helpers**:

```zig
// ‚ùå Too large (>70 lines)
pub fn parseCSV(buffer: []const u8) !DataFrame {
    // 100 lines of parsing logic
}

// ‚úÖ Correct - broken into helpers
pub fn parseCSV(buffer: []const u8) !DataFrame {
    const headers = try parseHeaders(buffer);
    const rows = try parseRows(buffer, headers.len);
    const types = try inferTypes(rows);
    return try buildDataFrame(headers, rows, types);
}

fn parseHeaders(buffer: []const u8) ![][]const u8 { /* ... */ }
fn parseRows(buffer: []const u8, col_count: u32) ![][]const u8 { /* ... */ }
fn inferTypes(rows: [][]const u8) ![]ValueType { /* ... */ }
```

---

## Common Code Patterns

### Pattern: CSV Field Parsing with State Machine

```zig
const ParserState = enum { Start, InField, InQuotedField, QuoteInQuoted };

fn parseField(parser: *CSVParser) ![]const u8 {
    std.debug.assert(parser.pos <= parser.buffer.len);
    std.debug.assert(parser.current_field.items.len == 0);

    while (parser.pos < parser.buffer.len) {
        const char = parser.buffer[parser.pos];
        parser.pos += 1;

        switch (parser.state) {
            .Start => { /* handle start */ },
            .InField => { /* handle unquoted field */ },
            .InQuotedField => { /* handle quoted field */ },
            .QuoteInQuoted => { /* handle quote escape */ },
        }
    }

    return try parser.current_field.toOwnedSlice();
}
```

### Pattern: Type Inference

```zig
fn inferColumnType(fields: [][]const u8) ValueType {
    std.debug.assert(fields.len > 0);
    std.debug.assert(fields.len <= 100); // Preview limit

    var all_int = true;
    var all_float = true;
    var all_bool = true;

    for (fields) |field| {
        if (!tryParseInt64(field)) all_int = false;
        if (!tryParseFloat64(field)) all_float = false;
        if (!tryParseBool(field)) all_bool = false;
    }

    if (all_int) return .Int64;
    if (all_float) return .Float64;
    if (all_bool) return .Bool;
    return .String;
}
```

### Pattern: Columnar Storage Conversion

```zig
fn rowsToColumns(
    allocator: std.mem.Allocator,
    rows: [][]const u8,
    types: []ValueType,
) ![]Series {
    std.debug.assert(rows.len > 0);
    std.debug.assert(types.len > 0);
    std.debug.assert(rows[0].len == types.len);

    const col_count = types.len;
    const row_count: u32 = @intCast(rows.len);

    var series = try allocator.alloc(Series, col_count);

    for (types, 0..) |typ, col_idx| {
        switch (typ) {
            .Float64 => {
                var data = try allocator.alloc(f64, row_count);
                for (rows, 0..) |row, row_idx| {
                    data[row_idx] = try std.fmt.parseFloat(f64, row[col_idx]);
                }
                series[col_idx] = Series{
                    .valueType = .Float64,
                    .data = .{ .Float64 = data },
                    .length = row_count,
                };
            },
            // ... other types
        }
    }

    return series;
}
```

---

## Error Handling

### Error Set Definitions

**Define clear error sets per module**:

```zig
// src/csv/parser.zig
pub const CSVError = error{
    InvalidFormat,
    UnexpectedEndOfFile,
    TooManyColumns,
    TooManyRows,
    InvalidQuoting,
    OutOfMemory,
};

// src/core/dataframe.zig
pub const DataFrameError = error{
    ColumnNotFound,
    TypeMismatch,
    IndexOutOfBounds,
    EmptyDataFrame,
    OutOfMemory,
};
```

### Error Context

**Provide context when returning errors**:

```zig
pub fn column(self: *const DataFrame, name: []const u8) !*const Series {
    std.debug.assert(self.series.len > 0);

    for (self.series, 0..) |*series, i| {
        if (std.mem.eql(u8, self.columns[i].name, name)) {
            return series;
        }
    }

    // Provide context in error
    std.log.err("Column not found: {s}", .{name});
    return error.ColumnNotFound;
}
```

---

## Memory Management

### Allocation Strategy

**DataFrame lifecycle**:

1. Create arena allocator
2. All DataFrame allocations use arena
3. Single `free()` call cleans up everything

```zig
pub const DataFrame = struct {
    arena: *std.heap.ArenaAllocator,
    // ... fields

    pub fn free(self: DataFrame) void {
        self.arena.deinit();
        self.allocator.destroy(self.arena);
    }
};
```

### Memory Tracking (Debug Builds)

```zig
const MemoryTracker = struct {
    allocator: std.mem.Allocator,
    total_allocated: u64 = 0,
    total_freed: u64 = 0,
    peak_usage: u64 = 0,

    pub fn alloc(self: *MemoryTracker, size: usize) ![]u8 {
        const mem = try self.allocator.alloc(u8, size);
        self.total_allocated += size;
        self.peak_usage = @max(self.peak_usage, self.current());
        return mem;
    }

    pub fn current(self: *const MemoryTracker) u64 {
        return self.total_allocated - self.total_freed;
    }
};
```

---

## Testing Patterns

### Testing Requirements

**CRITICAL**: Every code change MUST include tests. No exceptions.

**Test Coverage Requirements**:

1. **Unit Tests** - Every public function must have at least one unit test
2. **Error Case Tests** - Test error conditions (bounds, invalid input, parse failures)
3. **Integration Tests** - Test workflows (CSV ‚Üí DataFrame ‚Üí operations)
4. **Memory Leak Tests** - 1000 iterations of create/free cycles
5. **Conformance Tests** - RFC 4180 compliance using testdata files

**Test Location**: See `../CLAUDE.md` for test organization - all tests go in `src/test/`, NOT in source files

### Unit Test Template

**Every public function needs a unit test**:

```zig
// src/core/series.zig
test "Series.len returns correct length" {
    const allocator = std.testing.allocator;

    const data = try allocator.alloc(f64, 100);
    defer allocator.free(data);

    const series = Series{
        .name = "test",
        .valueType = .Float64,
        .data = .{ .Float64 = data },
        .length = 100,
    };

    try std.testing.expectEqual(@as(u32, 100), series.len());
}

test "Series.get checks bounds" {
    const allocator = std.testing.allocator;

    const data = try allocator.alloc(f64, 10);
    defer allocator.free(data);
    data[0] = 1.5;
    data[9] = 9.5;

    const series = Series{
        .name = "test",
        .valueType = .Float64,
        .data = .{ .Float64 = data },
        .length = 10,
    };

    // Valid access
    const val0 = series.get(0);
    try std.testing.expect(val0 != null);
    try std.testing.expectEqual(@as(f64, 1.5), val0.?.Float64);

    // Out of bounds should panic (in debug)
    // Cannot test assertion failure in release
}
```

### Memory Leak Test Template

```zig
test "DataFrame.free releases all memory" {
    const allocator = std.testing.allocator;

    var i: usize = 0;
    while (i < 1000) : (i += 1) {
        const df = try DataFrame.create(
            allocator,
            &[_]ColumnDesc{
                .{ .name = "col1", .valueType = .Float64 },
                .{ .name = "col2", .valueType = .Int64 },
            },
            100,
        );
        df.free();
    }

    // testing.allocator will report leaks automatically
}
```

### Integration Test Template

```zig
test "CSV parse ‚Üí DataFrame ‚Üí CSV export round-trip" {
    const allocator = std.testing.allocator;

    const original_csv = "name,age\nAlice,30\nBob,25\n";

    // Parse CSV
    const df = try DataFrame.fromCSVBuffer(allocator, original_csv, .{});
    defer df.free();

    // Export to CSV
    const exported_csv = try df.toCSV(allocator, .{});
    defer allocator.free(exported_csv);

    // Compare (may have whitespace differences)
    try std.testing.expectEqualStrings(original_csv, exported_csv);
}
```

### Test Examples for Common Issues

**1. Test Error Handling - Never Silent Failures**:

```zig
test "fillDataFrame fails on type mismatch instead of silently defaulting to 0" {
    const allocator = std.testing.allocator;

    // CSV with invalid integer value
    const csv = "age\nabc\n";  // "abc" is not a valid integer

    var parser = try CSVParser.init(allocator, csv, .{});
    defer parser.deinit();

    // ‚úÖ Should FAIL with error, NOT return DataFrame with age=0
    try std.testing.expectError(error.TypeMismatch, parser.toDataFrame());
}

test "columnNames propagates allocation error instead of returning empty array" {
    const allocator = std.testing.allocator;

    const cols = [_]ColumnDesc{
        ColumnDesc.init("age", .Int64, 0),
    };

    var df = try DataFrame.create(allocator, &cols, 100);
    defer df.deinit();

    // ‚úÖ Should return error, NOT empty array
    // (Use FailingAllocator to test this)
}
```

**2. Test BOM Handling**:

```zig
test "CSVParser skips UTF-8 BOM at start of file" {
    const allocator = std.testing.allocator;

    // CSV with BOM (0xEF 0xBB 0xBF) followed by content
    const csv_with_bom = "\xEF\xBB\xBFname,age\nAlice,30\n";

    var parser = try CSVParser.init(allocator, csv_with_bom, .{});
    defer parser.deinit();

    var df = try parser.toDataFrame();
    defer df.deinit();

    // ‚úÖ Should parse correctly, ignoring BOM
    try std.testing.expectEqual(@as(u32, 1), df.rowCount);
    try std.testing.expectEqualStrings("name", df.columnDescs[0].name);
}
```

**3. Test Line Ending Handling**:

```zig
test "CSVParser handles CRLF line endings" {
    const allocator = std.testing.allocator;

    const csv = "name,age\r\nAlice,30\r\nBob,25\r\n";

    var parser = try CSVParser.init(allocator, csv, .{});
    defer parser.deinit();

    var df = try parser.toDataFrame();
    defer df.deinit();

    try std.testing.expectEqual(@as(u32, 2), df.rowCount);
}

test "CSVParser handles CR-only line endings (old Mac format)" {
    const allocator = std.testing.allocator;

    const csv = "name,age\rAlice,30\rBob,25\r";

    var parser = try CSVParser.init(allocator, csv, .{});
    defer parser.deinit();

    var df = try parser.toDataFrame();
    defer df.deinit();

    try std.testing.expectEqual(@as(u32, 2), df.rowCount);
}

test "CSVParser handles LF-only line endings (Unix)" {
    const allocator = std.testing.allocator;

    const csv = "name,age\nAlice,30\nBob,25\n";

    var parser = try CSVParser.init(allocator, csv, .{});
    defer parser.deinit();

    var df = try parser.toDataFrame();
    defer df.deinit();

    try std.testing.expectEqual(@as(u32, 2), df.rowCount);
}
```

**4. Test Empty CSV Handling**:

```zig
test "toDataFrame allows empty CSV with headers only" {
    const allocator = std.testing.allocator;

    const csv = "name,age,score\n";  // Headers but no data rows

    var parser = try CSVParser.init(allocator, csv, .{});
    defer parser.deinit();

    var df = try parser.toDataFrame();
    defer df.deinit();

    // ‚úÖ Should create DataFrame with 0 rows, 3 columns
    try std.testing.expectEqual(@as(u32, 0), df.rowCount);
    try std.testing.expectEqual(@as(usize, 3), df.columns.len);
    try std.testing.expectEqualStrings("name", df.columnDescs[0].name);
    try std.testing.expectEqualStrings("age", df.columnDescs[1].name);
    try std.testing.expectEqualStrings("score", df.columnDescs[2].name);
}
```

**5. Test Type Inference Edge Cases**:

```zig
test "inferColumnType detects Float64 when preview has ints but later rows have decimals" {
    const allocator = std.testing.allocator;

    // First 50 rows are integers, row 51 has decimal
    var csv = std.ArrayList(u8).init(allocator);
    defer csv.deinit();

    try csv.appendSlice("value\n");
    var i: u32 = 0;
    while (i < 50) : (i += 1) {
        try csv.writer().print("{}\n", .{i});
    }
    try csv.appendSlice("50.5\n");  // Decimal at row 51

    var parser = try CSVParser.init(allocator, csv.items, .{
        .previewRows = 100,  // Preview should see row 51
    });
    defer parser.deinit();

    var df = try parser.toDataFrame();
    defer df.deinit();

    // ‚úÖ Should detect as Float64, not Int64
    try std.testing.expectEqual(ValueType.Float64, df.columns[0].valueType);
}
```

**6. Test Bounded Loops**:

```zig
test "nextField rejects field larger than MAX_FIELD_LENGTH" {
    const allocator = std.testing.allocator;

    // Create CSV with field exceeding 1MB
    var csv = std.ArrayList(u8).init(allocator);
    defer csv.deinit();

    try csv.appendSlice("data\n\"");
    // Append 2MB of 'A' characters
    var i: usize = 0;
    while (i < 2_000_000) : (i += 1) {
        try csv.append('A');
    }
    try csv.appendSlice("\"\n");

    var parser = try CSVParser.init(allocator, csv.items, .{});
    defer parser.deinit();

    // ‚úÖ Should reject with FieldTooLarge error
    try std.testing.expectError(error.FieldTooLarge, parser.toDataFrame());
}
```

**7. Test RFC 4180 Conformance** (using testdata files):

```zig
test "RFC 4180: 01_simple.csv" {
    const allocator = std.testing.allocator;
    const csv = @embedFile("../../../testdata/csv/rfc4180/01_simple.csv");

    var parser = try CSVParser.init(allocator, csv, .{});
    defer parser.deinit();

    var df = try parser.toDataFrame();
    defer df.deinit();

    // Validate structure
    try std.testing.expectEqual(@as(u32, 3), df.rowCount);
    try std.testing.expectEqual(@as(usize, 3), df.columns.len);
    try std.testing.expectEqualStrings("name", df.columnDescs[0].name);

    // Validate data
    const age_col = df.column("age").?;
    const ages = age_col.asInt64().?;
    try std.testing.expectEqual(@as(i64, 30), ages[0]);
    try std.testing.expectEqual(@as(i64, 25), ages[1]);
    try std.testing.expectEqual(@as(i64, 35), ages[2]);
}

test "RFC 4180: 04_embedded_newlines.csv - quoted fields with newlines" {
    const allocator = std.testing.allocator;
    const csv = "name,bio\n\"Alice\",\"Line 1\nLine 2\"\n";

    var parser = try CSVParser.init(allocator, csv, .{});
    defer parser.deinit();

    var df = try parser.toDataFrame();
    defer df.deinit();

    try std.testing.expectEqual(@as(u32, 1), df.rowCount);
    // Bio should contain the newline
    const bio_col = df.column("bio").?;
    // ‚úÖ Should preserve embedded newline in quoted field
}
```

---

## CSV Parsing - Data Processing Correctness

### RFC 4180 Compliance Checklist

**MUST HANDLE**:

1. ‚úÖ Quoted fields with embedded delimiters
2. ‚úÖ Quoted fields with embedded newlines
3. ‚úÖ Escaped quotes (`""` ‚Üí `"`)
4. ‚úÖ CRLF line endings
5. ‚ö†Ô∏è CR-only line endings (old Mac format)
6. ‚ùå UTF-8 BOM detection (0xEF 0xBB 0xBF)
7. ‚úÖ Empty fields
8. ‚ö†Ô∏è Empty CSV with headers only

### Critical CSV Parsing Issues

**1. BOM Detection**:

```zig
// ‚ùå MISSING - CSV may start with BOM
pub fn init(allocator: std.mem.Allocator, buffer: []const u8, opts: CSVOptions) !CSVParser {
    return CSVParser{
        .buffer = buffer,
        .pos = 0,  // Starts at 0, doesn't check for BOM
        // ...
    };
}

// ‚úÖ CORRECT - Skip BOM if present
pub fn init(allocator: std.mem.Allocator, buffer: []const u8, opts: CSVOptions) !CSVParser {
    std.debug.assert(buffer.len > 0);
    std.debug.assert(buffer.len <= MAX_CSV_SIZE);

    // Skip UTF-8 BOM if present
    const start_pos: u32 = if (buffer.len >= 3 and
        buffer[0] == 0xEF and buffer[1] == 0xBB and buffer[2] == 0xBF)
        3
    else
        0;

    return CSVParser{
        .buffer = buffer,
        .pos = start_pos,  // ‚úÖ Skip BOM
        // ...
    };
}
```

**2. Line Ending Normalization** - Avoid code duplication:

```zig
// ‚ùå WRONG - CRLF handling duplicated in 3 places
} else if (char == '\n' or char == '\r') {
    if (char == '\r' and self.pos < self.buffer.len and self.buffer[self.pos] == '\n') {
        self.pos += 1; // Skip LF in CRLF
    }
    // ... repeated 3 times in different states!
}

// ‚úÖ CORRECT - Centralized line ending detection
fn skipLineEnding(self: *CSVParser) void {
    std.debug.assert(self.pos <= self.buffer.len);

    if (self.pos >= self.buffer.len) return;

    const char = self.buffer[self.pos];
    if (char == '\r') {
        self.pos += 1;
        // Check for CRLF
        if (self.pos < self.buffer.len and self.buffer[self.pos] == '\n') {
            self.pos += 1;
        }
    } else if (char == '\n') {
        self.pos += 1;
    }
}

// Use consistently:
} else if (char == '\n' or char == '\r') {
    self.skipLineEnding();
    self.state = .EndOfRecord;
    return null;
}
```

**3. Empty CSV Handling**:

```zig
// ‚ùå WRONG - Returns error for headers-only CSV
if (data_rows.len == 0) {
    return error.NoDataRows;  // User just wanted schema!
}

// ‚úÖ CORRECT - Allow empty DataFrames
if (data_rows.len == 0) {
    // Create empty DataFrame with columns but no rows
    var df = try DataFrame.create(self.allocator, col_descs, 0);
    return df;
}
```

**4. Type Inference Edge Cases**:

```zig
// ‚ùå WRONG - 100 row preview too small for 1M row file
const preview_count = @min(self.opts.previewRows, @as(u32, @intCast(data_rows.len)));

// ‚úÖ BETTER - Adaptive preview based on file size
const preview_count = if (data_rows.len < 1000)
    @intCast(data_rows.len)
else if (data_rows.len < 100_000)
    @min(self.opts.previewRows, @intCast(data_rows.len / 10)) // 10% sample
else
    @min(self.opts.previewRows * 10, 10_000); // 1% sample, capped at 10K
```

**5. Int vs Float Ambiguity**:

```zig
// ‚ùå WRONG - "42" parses as Int, but row 101 might have "42.5"
if (all_int) return .Int64;
if (all_float) return .Float64;

// ‚úÖ CORRECT - Check for decimal indicators first
var has_decimals = false;
for (rows) |row| {
    if (col_idx >= row.len) continue;
    const field = row[col_idx];
    if (field.len == 0) continue;

    if (std.mem.indexOfScalar(u8, field, '.') != null or
        std.mem.indexOfScalar(u8, field, 'e') != null or
        std.mem.indexOfScalar(u8, field, 'E') != null) {
        has_decimals = true;
        break;
    }
}

// If any field has decimal, treat whole column as Float64
if (has_decimals) {
    // Validate all fields parse as float
    return .Float64;
} else {
    // Validate all fields parse as int
    return .Int64;
}
```

---

## Conformance Testing

### Running Conformance Tests

**Quick Command**:

```bash
# Test all CSV files in testdata/
zig build conformance
```

**What It Tests**:

- 10 RFC 4180 compliance tests (`testdata/csv/rfc4180/`)
- 7 edge case tests (`testdata/csv/edge_cases/`)
- 18 external test suites (`testdata/external/`)
  - csv-spectrum (15 tests)
  - PapaParse tests (5 tests)
  - csv-parsers-comparison (1 test)

**Total**: 35 CSV files

### How It Works

The conformance test system uses **runtime file discovery** instead of compile-time `@embedFile`:

```zig
// src/test/conformance_runner.zig
pub fn main() !void {
    const test_dirs = [_][]const u8{
        "testdata/csv/rfc4180",
        "testdata/csv/edge_cases",
        "testdata/external/csv-spectrum/csvs",
        "testdata/external/csv-parsers-comparison/src/main/resources",
        "testdata/external/PapaParse/tests",
    };

    for (test_dirs) |dir_path| {
        var dir = std.fs.cwd().openDir(dir_path, .{ .iterate = true }) catch continue;
        defer dir.close();

        var walker = dir.iterate();
        while (walker.next() catch null) |entry| {
            if (entry.kind != .file or !std.mem.endsWith(u8, entry.name, ".csv")) continue;

            // Test the CSV file
            const file = std.fs.cwd().openFile(full_path, .{}) catch continue;
            defer file.close();

            const content = file.readToEndAlloc(allocator, 1_000_000) catch continue;
            defer allocator.free(content);

            var parser = CSVParser.init(allocator, content, .{}) catch continue;
            defer parser.deinit();

            var df = parser.toDataFrame() catch |err| {
                std.debug.print("  ‚ùå FAIL: {s} - {}\n", .{ entry.name, err });
                continue;
            };
            defer df.deinit();

            std.debug.print("  ‚úÖ PASS: {s} ({} rows, {} cols)\n", .{
                entry.name, df.len(), df.columnCount()
            });
        }
    }
}
```

**Why Runtime Discovery**:

- ‚úÖ Avoids Zig 0.15 `@embedFile` package path restrictions
- ‚úÖ Automatically includes new test files (just drop them in testdata/)
- ‚úÖ Works with external test suites
- ‚úÖ No need to update source code when adding tests

### Current Results (MVP - Numeric Only)

**MVP Status** (0.1.0):

- ‚úÖ **6/35 passing** (numeric-only CSVs)
- ‚è∏Ô∏è **3 skipped** (deferred to 0.2.0 - string support)
- ‚ùå **26 failing** (contain string columns - expected for MVP)

**Skipped Tests**:

```zig
const string_tests = [_][]const u8{
    "04_embedded_newlines.csv", // Has string columns
    "08_no_header.csv",         // No header support yet
    "10_unicode_content.csv",   // String/unicode content
};
```

**Pass Rate**: 17% (expected for numeric-only MVP)

### Adding New Test Files

**To add a new conformance test**:

1. Drop the CSV file in `testdata/csv/rfc4180/` or `testdata/csv/edge_cases/`
2. Run `zig build conformance`
3. The test is automatically discovered and run

**No code changes needed!**

### Expected Results by Version

| Version     | Target Pass Rate | Reason                                |
| ----------- | ---------------- | ------------------------------------- |
| 0.1.0 (MVP) | 17% (6/35)       | Numeric columns only (Int64, Float64) |
| 0.2.0       | 80% (28/35)      | Add string column support             |
| 0.3.0       | 100% (35/35)     | Handle all edge cases                 |

### Debugging Failed Tests

**To debug a specific test file**:

```bash
# 1. Identify failing test from conformance output
zig build conformance | grep FAIL

# 2. Write unit test for that specific file
# src/test/unit/csv/conformance_test.zig
test "Debug: 02_quoted_fields.csv" {
    const csv = @embedFile("../../../testdata/csv/rfc4180/02_quoted_fields.csv");

    var parser = try CSVParser.init(std.testing.allocator, csv, .{});
    defer parser.deinit();

    // Add debug prints
    std.debug.print("\nParsing: {s}\n", .{csv});

    var df = try parser.toDataFrame();
    defer df.deinit();
}

# 3. Run unit test for detailed output
zig build test -Dtest-filter="Debug: 02_quoted_fields"
```

**Common Failure Patterns**:

1. **String columns** ‚Üí Wait for 0.2.0 (expected)
2. **Quoted fields** ‚Üí Check `ParserState.InQuotedField` logic
3. **Embedded newlines** ‚Üí Check `skipLineEnding()` in quoted state
4. **Empty fields** ‚Üí Check field finalization logic
5. **Type inference** ‚Üí Check `inferColumnType()` preview logic

---

**Last Updated**: 2025-10-27
**Related**: See `../CLAUDE.md` for project-wide guidelines and `../docs/` for full documentation
